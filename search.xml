<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Jetbrains系列产品重置试用方法</title>
      <link href="2020/12/28/Jetbrains%E7%B3%BB%E5%88%97%E4%BA%A7%E5%93%81%E9%87%8D%E7%BD%AE%E8%AF%95%E7%94%A8%E6%96%B9%E6%B3%95/"/>
      <url>2020/12/28/Jetbrains%E7%B3%BB%E5%88%97%E4%BA%A7%E5%93%81%E9%87%8D%E7%BD%AE%E8%AF%95%E7%94%A8%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="0x0-项目背景"><a href="#0x0-项目背景" class="headerlink" title="0x0. 项目背景"></a>0x0. 项目背景</h2><p>Jetbrains家的产品有一个很良心的地方，他会允许你试用<code>30</code>天（这个数字写死在代码里了）以评估是否你真的需要为它而付费。<br>但很多时候会出现一种情况：<strong>IDE并不能按照我们实际的试用时间来计算。</strong><br>我举个例子：如果我们开始了试用，然后媳妇生孩子要你回去陪产！陪产时我们并无空闲对IDE试用评估，它依旧算试用时间。（只是举个例子，或许你并没有女朋友）<br>发现了吗？你未能真的有<code>30</code>天来对它进行全面的试用评估，你甚至无法作出是否付费的决定。此时你会想要延长试用时间，然而Jetbrains并未提供相关功能，该怎么办？</p><p>事实上有一款插件可以实现这个功能，你或许可以用它来重置一下试用时间。<strong>但切记不要无休止的一直试用，这并不是这个插件的本意！</strong></p><h2 id="0x1-如何安装"><a href="#0x1-如何安装" class="headerlink" title="0x1. 如何安装"></a>0x1. 如何安装</h2><h3 id="1-插件市场安装："><a href="#1-插件市场安装：" class="headerlink" title="1). 插件市场安装："></a>1). 插件市场安装：</h3><ul><li>在<code>Settings/Preferences...</code> -&gt; <code>Plugins</code> 内手动添加第三方插件仓库地址：<code>https://plugins.zhile.io</code></li><li>搜索：<code>IDE Eval Reset</code>插件进行安装。如果搜索不到请注意是否做好了上一步？网络是否通畅？</li><li>插件会提示安装成功。</li></ul><h3 id="2-下载安装："><a href="#2-下载安装：" class="headerlink" title="2). 下载安装："></a>2). 下载安装：</h3><ul><li>点击这个<a href="https://plugins.zhile.io/files/ide-eval-resetter-2.1.6.zip">链接(v2.1.6)</a>下载插件的<code>zip</code>包（macOS可能会自动解压，然后把<code>zip</code>包丢进回收站）</li><li>通常可以直接把<code>zip</code>包拖进IDE的窗口来进行插件的安装。如果无法拖动安装，你可以在<code>Settings/Preferences...</code> -&gt; <code>Plugins</code> 里手动安装插件（<code>Install Plugin From Disk...</code>）</li><li>插件会提示安装成功。</li></ul><h2 id="0x2-如何使用"><a href="#0x2-如何使用" class="headerlink" title="0x2. 如何使用"></a>0x2. 如何使用</h2><ul><li>一般来说，在IDE窗口切出去或切回来时（窗口失去/得到焦点）会触发事件，检测是否长时间（<code>25</code>天）没有重置，给通知让你选择。（初次安装因为无法获取上次重置时间，会直接给予提示）</li><li>也可以手动唤出插件的主界面：<ul><li>如果IDE没有打开项目，在<code>Welcome</code>界面点击菜单：<code>Get Help</code> -&gt; <code>Eval Reset</code></li><li>如果IDE打开了项目，点击菜单：<code>Help</code> -&gt; <code>Eval Reset</code></li></ul></li><li>唤出的插件主界面中包含了一些显示信息，<code>2</code>个按钮，<code>1</code>个勾选项：<ul><li>按钮：<code>Reload</code> 用来刷新界面上的显示信息。</li><li>按钮：<code>Reset</code> 点击会询问是否重置试用信息并<strong>重启IDE</strong>。选择<code>Yes</code>则执行重置操作并<strong>重启IDE生效</strong>，选择<code>No</code>则什么也不做。（此为手动重置方式）</li><li>勾选项：<code>Auto reset before per restart</code> 如果勾选了，则自勾选后<strong>每次重启/退出IDE时会自动重置试用信息</strong>，你无需做额外的事情。（此为自动重置方式）</li></ul></li></ul><h2 id="0x3-如何更新"><a href="#0x3-如何更新" class="headerlink" title="0x3. 如何更新"></a>0x3. 如何更新</h2><h3 id="1-插件更新机制（推荐）："><a href="#1-插件更新机制（推荐）：" class="headerlink" title="1). 插件更新机制（推荐）："></a>1). 插件更新机制（推荐）：</h3><ul><li>IDE会自行检测其自身和所安装插件的更新并给予提示。如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新。</li><li>点击IDE的<code>Check for Updates...</code> 菜单手动检测IDE和所安装插件的更新。如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新。</li><li>插件更新可能会需要<strong>重启IDE</strong>。</li></ul><h3 id="2-手动更新："><a href="#2-手动更新：" class="headerlink" title="2). 手动更新："></a>2). 手动更新：</h3><ul><li>从本页面下载最新的插件<code>zip</code>包安装更新。参考本文：<code>下载安装</code>小节。</li><li>插件更新需要<strong>重启IDE</strong>。</li></ul><h2 id="0x4-一些说明"><a href="#0x4-一些说明" class="headerlink" title="0x4. 一些说明"></a>0x4. 一些说明</h2><ul><li><p>本插件默认不会显示其主界面，如果你需要，参考本文：<code>如何使用</code>小节。</p></li><li><p>市场付费插件的试用信息也会<strong>一并重置</strong>。</p></li><li><p>对于某些付费插件（如:<code>Iedis 2</code>,<code>MinBatis</code>）来说，你可能需要去取掉<code>javaagent</code></p><p>配置（如果有）后重启IDE：</p><ul><li>如果IDE没有打开项目，在<code>Welcome</code>界面点击菜单：<code>Configure</code> -&gt; <code>Edit Custom VM Options...</code> -&gt; 移除 <code>-javaagent:</code> 开头的行。</li><li>如果IDE打开了项目，点击菜单：<code>Help</code> -&gt; <code>Edit Custom VM Options...</code> -&gt; 移除 <code>-javaagent:</code> 开头的行。</li></ul></li><li><p>重置需要<strong>重启IDE生效</strong>！</p></li><li><p>重置后并不弹出<code>Licenses</code>对话框让你选择输入License或试用，这和之前的重置脚本/插件不同（省去这烦人的一步）。</p></li><li><p>如果长达<code>25</code>天不曾有任何重置动作，IDE会有<strong>通知询问</strong>你是否进行重置。</p></li><li><p>如果勾选：<code>Auto reset before per restart</code> ，重置是静默无感知的。</p></li><li><p>简单来说：勾选了<code>Auto reset before per restart</code>则无需再管，一劳永逸。</p></li></ul><h2 id="0x5-开源信息"><a href="#0x5-开源信息" class="headerlink" title="0x5. 开源信息"></a>0x5. 开源信息</h2><ul><li>插件是学习研究项目，源代码是开放的。源码仓库地址：<a href="https://gitee.com/pengzhile/ide-eval-resetter">Gitee</a>。</li><li>如果你有更好的想法，欢迎给我提<code>Pull Request</code>来共同研究完善。</li><li>插件源码使用：<code>GPL-2.0</code>开源协议发布。</li><li>插件使用<code>PHP</code>编写，毕竟<code>PHP</code>是世界上最好的编程语言！</li></ul><h2 id="0x6-支持的产品"><a href="#0x6-支持的产品" class="headerlink" title="0x6. 支持的产品"></a>0x6. 支持的产品</h2><ul><li><strong>IntelliJ IDEA</strong></li><li><strong>AppCode</strong></li><li><strong>CLion</strong></li><li><strong>DataGrip</strong></li><li><strong>GoLand</strong></li><li><strong>PhpStorm</strong></li><li><strong>PyCharm</strong></li><li><strong>Rider</strong></li><li><strong>RubyMine</strong></li><li><strong>WebStorm</strong></li></ul><p><strong>转载于：</strong> <a href="https://zhile.io/2020/11/18/jetbrains-eval-reset.html">https://zhile.io/2020/11/18/jetbrains-eval-reset.html</a></p>]]></content>
      
      
      
        <tags>
            
            <tag> tip </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>article title</title>
      <link href="2020/12/27/article-title/"/>
      <url>2020/12/27/article-title/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="2020/12/27/hello-world/"/>
      <url>2020/12/27/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Git的使用</title>
      <link href="2020/10/27/Git/"/>
      <url>2020/10/27/Git/</url>
      
        <content type="html"><![CDATA[<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><h1 id="0x0-GitHub用户信息"><a href="#0x0-GitHub用户信息" class="headerlink" title="0x0. GitHub用户信息"></a>0x0. GitHub用户信息</h1><pre class="language-shell" data-language="shell"><code class="language-shell">Username: fourgoldEmail address: lijinxinok@163.com密码：IELTS-rise-to-6.5-!验证邮箱：lijinxinok@163.com邮箱密码：qinni123！</code></pre><h1 id="0x1-Github常用命令"><a href="#0x1-Github常用命令" class="headerlink" title="0x1. Github常用命令"></a>0x1. Github常用命令</h1><h3 id="2-1初始化操作"><a href="#2-1初始化操作" class="headerlink" title="2.1初始化操作"></a>2.1初始化操作</h3><pre class="language-shell" data-language="shell"><code class="language-shell">#初始化本地仓库git init#查看隐藏文件.&#x2F;gitls -lAll .git&#x2F;#.git存放的是本地库相关的子目录以及文件#初始化本地配置 设置签名 这个签名和登录远程库和账号密码没有任何关系#global代表的是系统用户级别git config --global user.name JInxinLi#初始化本地邮箱$ git config --global user.email Jinxin@atguigu.com#签名的作用是区分不同操作者身份。用户的签名信息在每一个版本的提交信息中能够看到，以此确认本次提交是谁做的。</code></pre><p>就近原则:项目级别的优先于系统用户级别,采用项目级别的签名</p><p><strong>签名信息保存在哪里?</strong></p><pre class="language-bash" data-language="bash"><code class="language-bash">.&#x2F;git&#x2F;config</code></pre><p><strong>系统用户保存在哪里?</strong></p><pre class="language-bash" data-language="bash"><code class="language-bash">~&#x2F;.gitconfig</code></pre><h3 id="2-2实际操作"><a href="#2-2实际操作" class="headerlink" title="2.2实际操作"></a>2.2实际操作</h3><p>git add添加到暂存区还可以撤销</p><p>HEAD是一个指针</p><pre class="language-bash" data-language="bash"><code class="language-bash">#查看主文档 暂存区与工作区的状态 默认matser分支git status#添加暂存区git add#提交到本地库 hello.txt是文件名1 git commit -m &quot;version1.0&quot; hello.txt#推送matser开发线到远程仓库git push sparkStreaming master#将远程仓库的内容克隆到本地git clone http#拉取远程仓库内容git pull sparkStreaming master#查看历史版本 (HEAD -&gt; matser) HEAD是一个指针git loggit reflog#切换版本号git reset --hard 087a1a7#创建分支git branch hot-fix#查看分支git branch -v#切换分支git checkout hot-fix#合并分支#注意当前分支为mastergit merge hot-fix#冲突解决后提交git commit -m &quot;merge hot-fix&quot;####新建别名urlgit remote -vgit remote add origin https:&#x2F;&#x2F;url....git remote -v##推送git push origin master##克隆操作git clone url#回车#完整的把远程库下载到本地#创建origin远程地址别名#初始化本地库#邀请别人加入到协作组中#点击邀请,就变成了团队成员#pull &#x3D; fetch+mergegit fetch origin master#将远程库的master拉取下来#切换到origin master#查看远程的master分支[远程地址][远程分支]git checkout origin&#x2F;master#合并远程的master分支[远程地址][远程分支]git merge origin&#x2F;mastergit pull origin&#x2F;master</code></pre><p><strong>冲突解决</strong></p><p>当主分支已经提升了版本,而我们的clone的是旧版本,这个时候就已经无法推送</p><pre class="language-shell" data-language="shell"><code class="language-shell">#解决,先拿到远程的修改 如果不是最新版所做的修改,不能修改,必须先拉取git pull origin&#x2F;master#文件里东西修改git add [filename]git commit -m &quot;version2.0&quot;git push origin&#x2F;master</code></pre><p><strong>跨团队协作</strong></p><pre class="language-shell" data-language="shell"><code class="language-shell">#以第三者的身份先进行fork fork到自己的远程库#克隆到本地git clone url[自己的地址]#然后进行增加内容git commit -m &quot;...&quot; [filename]git push origin master#现在已经推送到自己的远程库#本地修改,然后推送到远程#new pull request#create new pull result#发送消息进行提交#经理 打开pull request#点击内容#两人可以聊天#点commits files changed#审核代码#merge pull request#点这里进行合并#合并的时候也要添加相关信息</code></pre><p>展示的时候显示了来源</p><h3 id="2-3查看历史记录log的方式"><a href="#2-3查看历史记录log的方式" class="headerlink" title="2.3查看历史记录log的方式"></a>2.3查看历史记录log的方式</h3><pre class="language-shell" data-language="shell"><code class="language-shell">#最完整的形式git log#日志以一个漂亮的格式进行显示git log --pretty&#x3D;oneline#hash值显示一部分git log --oneline#多屏幕显示控制方法#空格向下翻页#b向上翻页#q退出#在oneline的基础上显示了移动到某一个版本要移动几步git reflog</code></pre><p><img src="https://i.loli.net/2020/12/24/mvKrNGdHQwWt9Ty.png" alt="注意HEAD"></p><h3 id="2-4版本回退穿梭"><a href="#2-4版本回退穿梭" class="headerlink" title="2.4版本回退穿梭"></a>2.4版本回退穿梭</h3><p>管理历史记录的时候存在一个<strong>指针</strong>(HEAD)</p><p>我们可以把HEAD指针进行移动</p><pre class="language-shell" data-language="shell"><code class="language-shell">#切换版本号 git reset --hard 087a1a7</code></pre><h3 id="2-5三种操作的参数"><a href="#2-5三种操作的参数" class="headerlink" title="2.5三种操作的参数"></a>2.5<strong>三种操作</strong>的参数</h3><ol><li>基于索引值操作[推荐]</li><li>使用^符号:只能往后退</li></ol><pre class="language-shell" data-language="shell"><code class="language-shell">#回退一步git reset --hard HEAD^#回退三步git reset --hard HEAD^^^</code></pre><ol><li>使用~符号</li></ol><pre class="language-shell" data-language="shell"><code class="language-shell">#回退3步git reset --hard HEAD~3</code></pre><h3 id="2-6参数说明"><a href="#2-6参数说明" class="headerlink" title="2.6参数说明"></a>2.6参数说明</h3><p>reset命令的三个参数对比</p><pre class="language-shell" data-language="shell"><code class="language-shell">#查看本地帮助文档git help reset#命令--soft不会动index file(暂存区) and work tree(工作区)仅仅在本地库移动HEAD指针#将本地库后退--mixed在本地移动指针重置暂存区#将暂存区与本地库后退--hard移动指针重置缓存区重置工作区#全部后退</code></pre><h3 id="2-7永久删除文件的保存"><a href="#2-7永久删除文件的保存" class="headerlink" title="2.7永久删除文件的保存"></a>2.7永久删除文件的保存</h3><p>删除仅仅是一条记录,可以回退版本进行恢复</p><p>前提:删除前,文件存在时的状态提交到了本地库</p><pre class="language-shell" data-language="shell"><code class="language-shell">git reset -hard[指针位置]</code></pre><h3 id="2-8添加到暂存区的删除文件找回"><a href="#2-8添加到暂存区的删除文件找回" class="headerlink" title="2.8添加到暂存区的删除文件找回"></a>2.8添加到暂存区的删除文件找回</h3><pre class="language-shell" data-language="shell"><code class="language-shell">#暂存区与工作都是git reset --hard HEAD</code></pre><h3 id="2-9比较文件差异"><a href="#2-9比较文件差异" class="headerlink" title="2.9比较文件差异"></a>2.9比较文件差异</h3><pre class="language-shell" data-language="shell"><code class="language-shell">git diff test.txtgit diff [本地区中的历史版本][文件名]</code></pre><p><img src="https://i.loli.net/2020/12/24/GsheZUHS9PQ3zWN.png" alt="image-20201224171304996"></p><p>将工作区的文件个暂存区的文件进行比较</p><h3 id="2-10分支管理"><a href="#2-10分支管理" class="headerlink" title="2.10分支管理"></a>2.10分支管理</h3><p>在版本控制过程中,使用多条线控制任务的分支</p><p>分支的命名以feature开头 feature_bule</p><p>热修复的命名 hot_fix </p><p>分支能够同时并行推进多个功能的开发,提高开发效率</p><p>如果分支在开发过程中,如果某一个分支开发失败,不会对其他分支有任何影响,失败的分支删除重新开始</p><h3 id="2-11分支的具体操作"><a href="#2-11分支的具体操作" class="headerlink" title="2.11分支的具体操作"></a>2.11分支的具体操作</h3><p>master是默认分支</p><pre class="language-shell" data-language="shell"><code class="language-shell">#查看分支git branch -v#创建分支git branch hot_fix#切换分支git checkout hot_fix#合并分支的步骤#第一步:切换到接受修改的分支git checkout master#第二步:执行merge命令git merge hot_fix#解决冲突#第一步编辑文件,删除特殊符号#第二步把文件修改到满意#第三步 git add[文件名]#第四部 git commit</code></pre><h1 id="0x3-Git基本原理"><a href="#0x3-Git基本原理" class="headerlink" title="0x3. Git基本原理"></a>0x3. Git基本原理</h1><h2 id="3-1哈希算法"><a href="#3-1哈希算法" class="headerlink" title="3.1哈希算法"></a>3.1哈希算法</h2><pre class="mermaid">graph LR明文-->加密算法-->密文</pre><p>同一个数保证加密后得到同一个结果</p><p>输入数据细微变化会引起Hash巨大的变化</p><p>哈希算法不可逆</p><p>不管输入的数据的数据量有多大,输入同一个哈希算法,得到的加密结果长度固定</p><p>很多内容也会加密成得到的长度相同32位16进制数</p><p>Git底层采用的是SHA-1算法</p><p><strong>用途</strong>:哈希算法用于校验文件</p><h2 id="3-2-Git保存版本的机制"><a href="#3-2-Git保存版本的机制" class="headerlink" title="3.2 Git保存版本的机制"></a>3.2 Git保存版本的机制</h2><p>每个版本都会保存当前版本的文件状态</p><p>Git把数据看做是小型文件系统的一组快照,每次提交更新时Git都会对当前的全部文件制作一个快照并保存这个快照的索引</p><p>为了高效,如果文件没有修改,Git不再重新存储该文件,而是只保留一个链接指向之前的存储的文件,所以Git的工作方式可以称为快照流</p><h2 id="3-3Git如何管理分支"><a href="#3-3Git如何管理分支" class="headerlink" title="3.3Git如何管理分支"></a>3.3Git如何管理分支</h2><p>第一次提交是rootcommit</p><p>master与testing都算是指针,指向原来的对象</p><h1 id="0x4-idea使用GitHub"><a href="#0x4-idea使用GitHub" class="headerlink" title="0x4. idea使用GitHub"></a>0x4. idea使用GitHub</h1><h3 id="4-1创建同步忽略文件"><a href="#4-1创建同步忽略文件" class="headerlink" title="4.1创建同步忽略文件"></a>4.1创建同步忽略文件</h3><p>创建忽略规则文件xxxx.ignore（前缀名随便起）</p><p>这个文件的存放位置原则上在哪里都可以，</p><p>为了便于让~/.gitconfig文件引用，</p><p>建议也放在用户家目录下</p><p>xxxx.ignore文件内容如下：</p><h4 id="idea-ignore"><a href="#idea-ignore" class="headerlink" title="idea.ignore"></a>idea.ignore</h4><pre class="language-shell" data-language="shell"><code class="language-shell"># Compiled class file*.class# Log file*.log# BlueJ files*.ctxt# Mobile Tools for Java (J2ME).mtj.tmp&#x2F;# Package Files #*.jar*.war*.nar*.ear*.zip*.tar.gz*.rar# virtual machine crash logs, see http:&#x2F;&#x2F;www.java.com&#x2F;en&#x2F;download&#x2F;help&#x2F;error_hotspot.xmlhs_err_pid*.classpath.project.settingstarget.idea*.iml</code></pre><p>2）在.gitconfig文件中引用忽略配置文件（此文件在Windows的家目录中）</p><pre class="language-shell" data-language="shell"><code class="language-shell">[user]name &#x3D; ZhangJYemail &#x3D; ZhangJY@atguigu.com[core]excludesfile &#x3D; C:&#x2F;Users&#x2F;ZhangJY&#x2F;SH0720.ignore注意：这里要使用“正斜线（&#x2F;）”，不要使用“反斜线（\）”</code></pre><h2 id="4-2使用免密登录连接远程仓库"><a href="#4-2使用免密登录连接远程仓库" class="headerlink" title="4.2使用免密登录连接远程仓库"></a>4.2使用免密登录连接远程仓库</h2><p>配置免密登录时非常有必要的</p><p>首先要明白配置免密登录使用的SSH登录方式,使用RSA</p><p>免密登陆地址</p><pre class="language-shell" data-language="shell"><code class="language-shell">#1.进入家目录cd</code></pre><blockquote><p>89388@DESKTOP-CEH28KV MINGW64 ~</p></blockquote><pre class="language-shell" data-language="shell"><code class="language-shell">#2.删除.ssh目录rm -rvf .ssh</code></pre><blockquote><p>removed ‘.ssh/known_hosts’</p><p>removed directory ‘.ssh’</p></blockquote><pre class="language-shell" data-language="shell"><code class="language-shell">#3.生成免密密钥 -C +github账号ssh-keygen -t rsa -C lijinxinok@163.com</code></pre><pre class="language-shell" data-language="shell"><code class="language-shell">#4.查看公钥并复制公钥cat id_rsa.pub#复制公钥,注意有坑,在命令行复制容易出问题#可以去源文件的地方使用nodpad++打开</code></pre><pre class="language-shell" data-language="shell"><code class="language-shell">#5.添加公钥到github#如图</code></pre><p><img src="https://i.loli.net/2020/12/25/am5XnUMoeWY7G2x.png" alt=" 1606477780968"></p><p>然后将公钥复制进去就可以了</p><p>注意push的时候要使用SSH地址哦</p><p><img src="https://i.loli.net/2020/12/25/4PqjRpcbdrewtGv.png" alt="免密登陆地址"></p><pre class="language-shell" data-language="shell"><code class="language-shell">#6.查看当前所有远程地址别名git remote -v </code></pre><p>然后将远程登录的SSH复制,添加别名</p><pre class="language-shell" data-language="shell"><code class="language-shell">#7.别名 远程地址git remote add SparkStreaming http:ssh登录地址</code></pre><p>注意有坑,这里时ssh登录地址</p><p>接下来就可以测试了</p><pre class="language-shell" data-language="shell"><code class="language-shell">#8.测试一下git add hello.txtgit push SparkStreaming master</code></pre><h2 id="4-3-Git结构"><a href="#4-3-Git结构" class="headerlink" title="4.3.Git结构"></a>4.3.Git结构</h2><pre class="mermaid">graph TD历史版本---本地库临时存储---暂存区写代码---工作区工作区--git add-->暂存区暂存区--git commit-->本地库</pre><h2 id="4-4Git和代码托管中心"><a href="#4-4Git和代码托管中心" class="headerlink" title="4.4Git和代码托管中心"></a>4.4Git和代码托管中心</h2><h4 id="局域网环境"><a href="#局域网环境" class="headerlink" title="局域网环境"></a>局域网环境</h4><p>GitLab</p><h4 id="外网络环境"><a href="#外网络环境" class="headerlink" title="外网络环境"></a>外网络环境</h4><p>GitHub</p><p>码云</p><h2 id="4-5-本地与内部协作"><a href="#4-5-本地与内部协作" class="headerlink" title="4.5 本地与内部协作"></a>4.5 本地与内部协作</h2><h4 id="团队内部协作"><a href="#团队内部协作" class="headerlink" title="团队内部协作"></a>团队内部协作</h4><p>加入团队可以增加权限</p><h4 id="跨团队协作"><a href="#跨团队协作" class="headerlink" title="跨团队协作"></a>跨团队协作</h4><h2 id="4-6从零到一使用IDEA"><a href="#4-6从零到一使用IDEA" class="headerlink" title="4.6从零到一使用IDEA"></a>4.6从零到一使用IDEA</h2><h3 id="创建本地库"><a href="#创建本地库" class="headerlink" title="创建本地库"></a>创建本地库</h3><p>将一个文件添加到ignore忽视</p><pre class="language-shell" data-language="shell"><code class="language-shell">#将数据添加到ignoregit add to .gitignore</code></pre><p>将文件添加exclude</p><pre class="language-shell" data-language="shell"><code class="language-shell">git add to exclude</code></pre><h3 id="创建版本"><a href="#创建版本" class="headerlink" title="创建版本"></a>创建版本</h3><pre class="language-shell" data-language="shell"><code class="language-shell">commitversion-0.1 Copy Revison Number</code></pre><h3 id="回退版本"><a href="#回退版本" class="headerlink" title="回退版本"></a>回退版本</h3><p><img src="https://i.loli.net/2020/12/25/oyQbqeJjfGzdlF5.png" alt="回退版本图"></p><p>然后将版本哈希值粘贴到HEAD地方</p><h3 id="创建分支以及合并分支"><a href="#创建分支以及合并分支" class="headerlink" title="创建分支以及合并分支"></a>创建分支以及合并分支</h3><p>创建分支</p><p><img src="https://i.loli.net/2020/12/25/48awkZFMH3X7q2B.png" alt="image-20201225163340577"></p><p>合并分支</p><p><img src="https://i.loli.net/2020/12/25/DyPaoRHQ5Ud2Y63.png" alt="image-20201225163935837"></p><h3 id="如何在idea里解决分支冲突"><a href="#如何在idea里解决分支冲突" class="headerlink" title="如何在idea里解决分支冲突"></a>如何在idea里解决分支冲突</h3><p>merge</p><h3 id="添加合作伙伴"><a href="#添加合作伙伴" class="headerlink" title="添加合作伙伴"></a>添加合作伙伴</h3><p>setting</p><p>manage access</p><h1 id="0x5-HEXO个人博客"><a href="#0x5-HEXO个人博客" class="headerlink" title="0x5. HEXO个人博客"></a>0x5. HEXO个人博客</h1><pre class="language-bash" data-language="bash"><code class="language-bash">git config --global user.name &quot;godweiyang&quot;git config --global user.email &quot;792321264@qq.com&quot;ssh-keygen -t rsa -C &quot;lijinxinok@163.com&quot;</code></pre><h1 id="0x6-配置图床"><a href="#0x6-配置图床" class="headerlink" title="0x6. 配置图床"></a>0x6. 配置图床</h1><p><img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_20_12/%E6%B5%8B%E8%AF%95.png" alt="测试图"></p><p>加油</p>]]></content>
      
      
      
        <tags>
            
            <tag> git idea </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="2020/09/01/Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01/"/>
      <url>2020/09/01/Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop入门-笔记总结"><a href="#Hadoop入门-笔记总结" class="headerlink" title="Hadoop入门-笔记总结"></a>Hadoop入门-笔记总结</h1><h2 id="学习目标："><a href="#学习目标：" class="headerlink" title="学习目标："></a>学习目标：</h2><ul><li> 了解大数据的概念以及应用场景和发展前景（这部分还是会讲故事即可）</li><li> 初步掌握大数据部门业务分析流程以及完整的大数据部门的组织架构（还是了解讲故事…）</li><li> 通俗易懂的说明白Hadoop的概念以及发展历史</li><li> 掌握Hadoop的前后的版本迭代更新以及Hadoop的优势</li><li> <strong>重点理解Hadoop框架的三大组成部分，并准确的表述各自的作用</strong></li><li> 掌握大数据生态的概念</li><li> <strong>熟练操作Hadoop运行环境的搭建（重点掌握）</strong></li><li> <strong>熟练掌握Hadoop的运行模式（重点掌握）</strong></li><li> 掌握Hadoop2.x和Hadoop3.x版本的差异</li><li> 能够对Hadoop的源码进行编译</li><li> <strong>掌握常见的错误和问题（重点）</strong></li></ul><h2 id="一、大数据概论"><a href="#一、大数据概论" class="headerlink" title="一、大数据概论"></a>一、大数据概论</h2><p><strong>前言：</strong>这部分主要讲解的就是大数据的概念，以及大数据的应用领域和发展前景，要求大家能够用自己的话去描述，讲给别人听即可！</p><h3 id="1-大数据的发展史"><a href="#1-大数据的发展史" class="headerlink" title="1.大数据的发展史"></a>1.大数据的发展史</h3><figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">In pioneer days they used oxen for heavy pulling, and when one ox couldn’t budge a log,they didn’t try to grow a larger ox. We shouldn’t be trying for bigger computers, but formore systems of computers.</span><br><span class="line">—Grace Hopper</span><br></pre></td></tr></table></figure><h3 id="2-大数据的概念"><a href="#2-大数据的概念" class="headerlink" title="2.大数据的概念"></a>2.大数据的概念</h3><p>​    大数据（big data），IT行业术语，是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p><p>​    简单的讲 <strong>大数据</strong> 就是海量数据，我们想要利用这海量数据，必然要对它进行<strong>存储</strong> ，然后又想让其实现价值，必须得通过 <strong>分析计算</strong> 得到结果，而分析计算也不能没有时间限制，那就得在合理的时间内分析计算。最后一句话就是 <strong>大数据技术就是来完成海量数据的存储以及对海量数据在合理时间内进行分析运算的</strong></p><p>​    最小的基本单位是bit，按顺序给出所有单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB，它们按照进率1024（2的十次方）来计算：</p><p>8bit= 1Byte</p><p>1KB= 1,024 Bytes</p><p>1MB= 1,024 KB = 1,048,576 Bytes</p><p>1GB= 1,024 MB = 1,048,576 KB</p><p><strong>1TB= 1,024 GB = 1,048,576 MB</strong></p><p><strong>1PB= 1,024 TB = 1,048,576 GB</strong></p><p><strong>1EB= 1,024 PB = 1,048,576 TB</strong></p><p>1ZB= 1,024 EB = 1,048,576 PB</p><p>1YB= 1,024 ZB = 1,048,576 EB</p><p>1BB= 1,024 YB = 1,048,576 ZB</p><p>1NB= 1,024 BB = 1,048,576 YB</p><p>1 DB = 1,024 NB = 1,048,576 BB</p><h3 id="3-大数据的特点"><a href="#3-大数据的特点" class="headerlink" title="3.大数据的特点"></a>3.大数据的特点</h3><p>​    <strong>3.1大量（Volume）</strong></p><p>​    想要贴近大数据的概念，必然要求海量数据，用量化的单位来描述的话至少也得PB级别的起步。</p><p>​    <strong>3.2高速（Velocity）</strong></p><p>​    所谓的高速是指海量数据产生的速度是非常快的，例如 <strong>天猫双十一</strong> 大约1分钟左右成交100亿的，100亿背后所涉及的数据可想而知。同时数据产生速度的也要求我们对数据的处理的效率要跟上节奏才可以。</p><p>​    <strong>3.3多样（Variety）</strong></p><p>​    多样是指数据的体现形式是多样化的，大体分为三种形式  <strong>结构化数据</strong>  <strong>半结构化数据</strong>  <strong>非结构化化数据</strong>，这些所说的基本上都是原始数据，我们将来要想地数据更高效的运算都会对原始数据进行清洗。</p><p>​    <strong>3.4低价值密度（Value）</strong></p><p>​    在通常情况下，面对海量数据，往往我们需要的可能只是其中的一小部分，这就是说 <strong>价值密度的高低和数据总量是成反比的</strong> 这也是大数据比较显著的一个特点，所以 高效快速的对有价值的数据进行<strong>“提纯”</strong> 成为目前大数据领域一个攻坚破阻的难题。</p><h3 id="4-大数据的应用场景"><a href="#4-大数据的应用场景" class="headerlink" title="4.大数据的应用场景"></a>4.大数据的应用场景</h3><p>​    本章节主要了解大数据的真实应用场景和领域。这部分大家作为了解即可，推荐下面一片文章作为参考！</p><p>​    <a href="https://www.jianshu.com/p/bb989c2fbc76">https://www.jianshu.com/p/bb989c2fbc76</a></p><h3 id="5-大数据的发展前景"><a href="#5-大数据的发展前景" class="headerlink" title="5.大数据的发展前景"></a>5.大数据的发展前景</h3><p>​    大数据行业的前景毋庸置疑是非常好的，从国家政策的推动再到行业的人才缺口以及未来的发展趋势都让大数据成为一个很有前途的专业。但是还是要求大家稳扎稳打 技术到家 才能翻江倒海！</p><h3 id="6-大数据部门业务流程分析"><a href="#6-大数据部门业务流程分析" class="headerlink" title="6.大数据部门业务流程分析"></a>6.大数据部门业务流程分析</h3><p>​    本小节主要介绍在工作当中我们将来完成一个项目的业务流程，我们大数据的工作在哪一环节崭露头角！我们大数据主要任务就是根据具体的需求对数据进行存储和分析运算，最后获取想要的数据结果。</p><h3 id="7-大数据部门组织结构（重点）"><a href="#7-大数据部门组织结构（重点）" class="headerlink" title="7.大数据部门组织结构（重点）"></a>7.大数据部门组织结构（重点）</h3><p>​    这一小节主要阐述一个公司通常大数据部门的智能分布，可以参考下图：</p><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200815225821434.png" alt="image-20200815225821434"></p><h2 id="二、从Hadoop框架讨论大数据生态"><a href="#二、从Hadoop框架讨论大数据生态" class="headerlink" title="二、从Hadoop框架讨论大数据生态"></a>二、从Hadoop框架讨论大数据生态</h2><h3 id="1-Hadoop的概念"><a href="#1-Hadoop的概念" class="headerlink" title="1. Hadoop的概念"></a>1. Hadoop的概念</h3><p>​    <strong>理解Hadoop是什么要从两个层面去入手：</strong></p><p>​    <strong>1.1 狭义：</strong>Hadoop是Apache旗下的一个用java语言实现开源软件框架，是一个开发和运行处理大规模数据的软件平台。允许使用简单的编程模型在大量计算机集群上对大型数据集进行分布式处理。它的核心组件有：</p><p>HDFS（分布式文件系统）：解决海量数据存储</p><p>YARN（作业调度和集群资源管理的框架）：解决资源任务调度</p><p>MAPREDUCE（分布式运算编程框架）：解决海量数据计算</p><p>​    <img src="Hadoop笔记总结-01.assets/image-20200815231415210.png" alt="image-20200815231415210" style="zoom:50%;" /></p><p>​    <strong>1.2 广义：</strong>广义上来说，Hadoop通常是指一个更广泛的概念——Hadoop生态圈。 </p><p>​    <img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200815231602113.png" alt="image-20200815231602113"></p><p>当下的Hadoop已经成长为一个庞大的体系，随着生态系统的成长，新出现的项目越来越多，其中不乏一些非Apache主管的项目，这些项目对HADOOP是很好的补充或者更高层的抽象。比如：</p><p>HDFS：分布式文件系统</p><p>MAPREDUCE：分布式运算程序开发框架</p><p>HIVE：基于HADOOP的分布式数据仓库，提供基于SQL的查询数据操作</p><p>HBASE：基于HADOOP的分布式海量数据库</p><p>ZOOKEEPER：分布式协调服务基础组件</p><p>Mahout：基于mapreduce/spark/flink等分布式运算框架的机器学习算法库</p><p>OOZIE：工作流调度框架</p><p>Sqoop：数据导入导出工具（比如用于mysql和HDFS之间）</p><p>FLUME：日志数据采集框架</p><p>IMPALA：基于hive的实时sql查询分析</p><h3 id="2-Hadoop的发展史"><a href="#2-Hadoop的发展史" class="headerlink" title="2. Hadoop的发展史"></a>2. Hadoop的发展史</h3><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200814220122350.png" alt="image-20200814220122350"></p><ol><li><p>2002年10月，Doug Cutting和Mike Cafarella创建了开源网页爬虫项目Nutch。</p></li><li><p>2003年10月，Google发表Google File System论文。</p></li><li><p>2004年7月，Doug Cutting和Mike Cafarella在Nutch中实现了类似GFS的功能，即后来HDFS的前身。</p></li><li><p>2004年10月，Google发表了MapReduce论文。</p></li><li><p>2005年2月，Mike Cafarella在Nutch中实现了MapReduce的最初版本。</p></li><li><p>2005年12月，开源搜索项目Nutch移植到新框架，使用MapReduce和NDFS在20个节点稳定运行。</p></li><li><p>2006年1月，Doug Cutting加入雅虎，Yahoo!提供一个专门的团队和资源将Hadoop发展成一个可在网络上运行的系统。</p></li><li><p>2006年2月，Apache Hadoop项目正式启动以支持MapReduce和HDFS的独立发展。</p></li><li><p>2006年3月，Yahoo!建设了第一个Hadoop集群用于开发。</p></li></ol><p>10.2006年4月，第一个Apache Hadoop发布。</p><p>11.2006年11月，Google发表了Bigtable论文，激起了Hbase的创建。</p><p>12.2007年10月，第一个Hadoop用户组会议召开，社区贡献开始急剧上升。</p><p>13.2007年，百度开始使用Hadoop做离线处理。</p><p>14.2007年，中国移动开始在“大云”研究中使用Hadoop技术。</p><p>15.2008年，淘宝开始投入研究基于Hadoop的系统——云梯，并将其用于处理电子商务相关数据。</p><p>16.2008年1月，Hadoop成为Apache顶级项目。</p><p>17.2008年2月，Yahoo!运行了世界上最大的Hadoop应用，宣布其搜索引擎产品部署在一个拥有1万个内核的Hadoop集群上。</p><p>18.2008年4月，在900个节点上运行1TB排序测试集仅需209秒，成为世界最快。</p><p>19.2008年8月，第一个Hadoop商业化公司Cloudera成立。</p><p>20.2008年10月，研究集群每天装载10TB的数据。</p><p>21.2009 年3月，Cloudera推出世界上首个Hadoop发行版——CDH（Cloudera’s Distribution including Apache Hadoop）平台，完全由开放源码软件组成。</p><p>22.2009年6月，Cloudera的工程师Tom White编写的《Hadoop权威指南》初版出版，后被誉为Hadoop圣经。</p><p>23.2009年7月 ，Hadoop Core项目更名为Hadoop Common;</p><p>24.2009年7月 ，MapReduce 和 Hadoop Distributed File System (HDFS) 成为Hadoop项目的独立子项目。</p><p>25.2009年8月，Hadoop创始人Doug Cutting加入Cloudera担任首席架构师。</p><p>26.2009年10月，首届Hadoop World大会在纽约召开。</p><p>27.2010年5月，IBM提供了基于Hadoop 的大数据分析软件——InfoSphere BigInsights，包括基础版和企业版。</p><p>28.2011年3月，Apache Hadoop获得Media Guardian Innovation Awards媒体卫报创新奖</p><p>29.2012年3月，企业必须的重要功能HDFS NameNode HA被加入Hadoop主版本。</p><p>30.2012年8月，另外一个重要的企业适用功能YARN成为Hadoop子项目。</p><p>31.2014年2月，Spark逐渐代替MapReduce成为Hadoop的缺省执行引擎，并成为Apache基金会顶级项目。</p><p>2017年12月，Release 3.0.0 generally available</p><h3 id="3-Hadoop三大发行版本"><a href="#3-Hadoop三大发行版本" class="headerlink" title="3. Hadoop三大发行版本"></a>3. Hadoop三大发行版本</h3><p><strong>3.1 Apache</strong></p><p>企业实际使用并不多。最原始（基础）版本。这是学习hadoop的基础。</p><p><strong>3.2 cloudera</strong></p><p>对hadoop的升级，打包，开发了很多框架。flume、hue、impala都是这个公司开发</p><p>2008 年成立的 Cloudera 是最早将 Hadoop 商用的公司，为合作伙伴提 供 Hadoop 的商用解决方案，主要是包括支持，咨询服务，培训。</p><p>2009年Hadoop的创始人 Doug Cutting也加盟 Cloudera公司。Cloudera 产品主要 为 CDH，Cloudera Manager，Cloudera Support</p><p>CDH是Cloudera的Hadoop发行版，完全开源，比Apache Hadoop在兼容性，安全 性，稳定性上有所增强。</p><p>Cloudera Manager是集群的软件分发及管理监控平台，可以在几个小时内部署 好一个Hadoop集群，并对集群的节点及服务进行实时监控。Cloudera Support即 是对Hadoop的技术支持。</p><p>Cloudera 的标价为每年每个节点4000美元。Cloudera开发并贡献了可实时处理大 数据的Impala项目。</p><p><strong>3.3 Hortonworks</strong></p><p>2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建</p><p>公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工 程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop 80%的代码。</p><p>雅虎工程副总裁、雅虎Hadoop开发团队负责人Eric Baldeschwieler出任<br> Hortonworks的首席执行官。</p><p>Hortonworks 的主打产品是Hortonworks Data Platform (HDP)，也同样是100%开 源的产品，HDP除常见的项目外还包含了Ambari，一款开源的安装和管理系统</p><p>HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook 开源的Hive中<br> 。Hortonworks的Stinger开创性地极大地优化了Hive项目。Hortonworks为入门提 供了一个非常好的，易于使用的沙盒。</p><p>Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能 够在包括Windows Server和Windows Azure在内的Microsoft Windows平台上本地 运行。定价以集群为基础，每10个节点每年为12500美元。</p><h3 id="4-Hadoop的优势"><a href="#4-Hadoop的优势" class="headerlink" title="4. Hadoop的优势"></a>4. Hadoop的优势</h3><h5 id="4-1-高可靠性"><a href="#4-1-高可靠性" class="headerlink" title="4.1 高可靠性"></a>4.1 高可靠性</h5><p> Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失。</p><h5 id="4-2-高可扩展性"><a href="#4-2-高可扩展性" class="headerlink" title="4.2 高可扩展性"></a>4.2 高可扩展性</h5><p> 在集群间分配任务数据，可方便的扩展数以千计的节点。</p><h5 id="4-3-高效性"><a href="#4-3-高效性" class="headerlink" title="4.3 高效性"></a>4.3 高效性</h5><p> 在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</p><h5 id="4-4-高容错性"><a href="#4-4-高容错性" class="headerlink" title="4.4 高容错性"></a>4.4 高容错性</h5><p> 能够自动将失败的任务重新分配。</p><h3 id="5-Hadoop框架组成"><a href="#5-Hadoop框架组成" class="headerlink" title="5. Hadoop框架组成"></a>5. Hadoop框架组成</h3><p>Hadoop是一个能够对大量数据进行分布式处理的软件框架，以一种可靠、高效、可伸缩的方式进行数据处理，其有许多元素构成，以下是其组成元素：</p><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200816214808801.png" alt="image-20200816214808801"></p><p><strong>注意：</strong> 通过上图我们要掌握的重点是Hadoop是由核心的三大组件构成的，在hadoop1.x的版本中 只有两大组件分别是 <strong>HDFS(负责文件的存储)**和</strong>MapReduce(负责文件的计算和资源调度)** 。后来在hadoop2.x的时候出于架构的解耦考虑以及让 资源调度 工作能更加灵活多样化就把 原来MapReduce中的负责资源调度的功能剥离出来 单独形成 Yarn 这个核心组件。</p><h4 id="5-1HDFS理论概述"><a href="#5-1HDFS理论概述" class="headerlink" title="5.1HDFS理论概述"></a>5.1HDFS理论概述</h4><p><strong>HDFS:</strong> Hadoop Distributed File System(hadoop分布式文件系统)</p><p><strong>注意：</strong> 本小节主要是从理论的角度先去理解HDFS的概念，HDFS中还包含很多概念我们逐个来分析理解。</p><p><strong>1.HDFS的特点：</strong> </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 保存多个副本，且提供容错机制，副本丢失或宕机自动恢复。默认存3份。</span><br><span class="line"></span><br><span class="line">2. 运行在廉价的机器上。</span><br><span class="line"></span><br><span class="line">3. 适合大数据的处理。HDFS默认会将文件分割成block，64M为1个block。</span><br><span class="line">   然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。如果小文件太多，那内存的负担会很  重。</span><br></pre></td></tr></table></figure><p><strong>2.在HDFS中有三个重要的角色相互协调工作，分别是NameNode  SecondaryNameNode   DataNode</strong> </p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.NameNode   Master节点，大领导。</span><br><span class="line">  -- 管理数据块映射；</span><br><span class="line">  -- 处理客户端的读写请求；</span><br><span class="line">  -- 配置副本策略；</span><br><span class="line">  -- 管理HDFS的名称空间。 </span><br><span class="line">  -- namenode 内存中存储的是 &#x3D; fsimage + edits。</span><br><span class="line">     其中fsimage元数据镜像文件（文件系统的目录树），edits元数据的操作日志（针对文件系统做的修改操  作记录）</span><br><span class="line">  总之：NameNode很重要，在海量数据的存储和管理，NameNode就相当于是所有数据的描述或者指针，有了它才能进一步操作真实数据。</span><br><span class="line">  </span><br><span class="line">2.SecondaryNameNode  它是个小弟，分担大哥NameNode的工作量。</span><br><span class="line">  -- SecondaryNameNode负责定时默认1小时，从namenode上，获取fsimage和edits来进行合并，然后再      发送给namenode。减少namenode的工作量。</span><br><span class="line">  -- NameNode的冷备份。</span><br><span class="line">  </span><br><span class="line">3.DataNode  真实数据的存储位置</span><br><span class="line">  -- 存储client发来的数据块block；</span><br><span class="line">  -- 执行数据块的读写操作。</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="5-2-YARN架构概述"><a href="#5-2-YARN架构概述" class="headerlink" title="5.2 YARN架构概述"></a>5.2 YARN架构概述</h4><p>​        本小节主要了解YARN架构中重要的几个 组件。本次接触YARN不要求掌握其本质原理，只要求混个脸熟，大概了解YARN的作用以及组成部分，为后面的学习建立基础。</p><p>​    <strong>1.为什么要用YARN？</strong></p><p>​        首先我们要知道的是在Hadoop1.x时代 是没有YARN的，那时候所有的数据计算以及计算过程的任务分配和资源调度都是在MapReduce中进行的，这样存在很多问题和隐患，典型的就是JobTracker容易存在单点故障和JobTracker负担重，既要负责资源管理，又要进行作业调度；当需处理太多任务时，会造成过多的资源消耗。所以在Hadoop2.x的时候，推出了YARN这套系统，其主要目的就是将Hadoop中的资源调度功能独立的分离出来，这样更方便扩展，也能高效合理的调度资源。</p><p>​    <strong>2.YARN中的几大角色</strong></p><p>​        <img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200818184449616.png" alt="image-20200818184449616"></p><p>​        <strong>– ResourceManager</strong></p><p>​            YARN 分层结构的本质是 ResourceManager。这个实体控制整个集群并管理应用程序向基础计算资源的分配。ResourceManager 将各个资源部分（计算、内存、带宽等）精心安排给基础 NodeManager（YARN 的每节点代理）。ResourceManager 还与 ApplicationMaster 一起分配资源，与 NodeManager 一起启动和监视它们的基础应用程序。在此上下文中，ApplicationMaster 承担了以前的 TaskTracker 的一些角色，ResourceManager 承担了 JobTracker 的角色。</p><p>​            <strong>总的来说，RM有以下作用：</strong></p><pre><code>        1）处理客户端请求        2）启动或监控ApplicationMaster</code></pre><p>​            3）监控NodeManager</p><pre><code>        4）资源的分配与调度</code></pre><p>​        <strong>– NodeManager</strong></p><p>​                ApplicationMaster 管理在YARN内运行的每个应用程序实例。ApplicationMaster 负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器的执行和资源使用（CPU、内存等的资源分配）。请注意，尽管目前的资源更加传统（CPU 核心、内存），但未来会带来基于手头任务的新资源类型（比如图形处理单元或专用处理设备）。从 YARN 角度讲，ApplicationMaster 是用户代码，因此存在潜在的安全问题。YARN 假设 ApplicationMaster 存在错误或者甚至是恶意的，因此将它们当作无特权的代码对待。</p><p>​                <strong>总的来说,AM有以下作用：</strong></p><pre><code>            1）负责数据的切分</code></pre><p>​                2）为应用程序申请资源并分配给内部的任务</p><p>​                3）任务的监控与容错</p><p>​        <strong>– ApplicationMaster</strong></p><p>​                NodeManager管理YARN集群中的每个节点。NodeManager 提供针对集群中每个节点的服务，从监督对一个容器的终生管理到监视资源和跟踪节点健康。MRv1 通过插槽管理 Map 和 Reduce 任务的执行，而 NodeManager 管理抽象容器，这些容器代表着可供一个特定应用程序使用的针对每个节点的资源。</p><p>​                <strong>总的来说，NM有以下作用：</strong></p><pre><code>            1）管理单个节点上的资源            2）处理来自ResourceManager的命令            3）处理来自ApplicationMaster的命令</code></pre><p>​        <strong>– Container</strong></p><p>​            Container 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。</p><p>​            <strong>总的来说，Container有以下作用：</strong></p><pre><code>       1）对任务运行环境进行抽象，封装CPU、内存等多维度的资源以及环境变量、启动命令等任务运行相关的信息</code></pre><p><strong>总结：要使用一个 YARN 集群，首先需要一个包含应用程序的客户的请求。ResourceManager 协商一个容器的必要资源，启动一个 ApplicationMaster 来表示已提交的应用程序。通过使用一个资源请求协议，ApplicationMaster 协商每个节点上供应用程序使用的资源容器。执行应用程序时，ApplicationMaster 监视容器直到完成。当应用程序完成时，ApplicationMaster 从 ResourceManager 注销其容器，执行周期就完成了。</strong></p><h4 id="5-3-MapReduce架构概述"><a href="#5-3-MapReduce架构概述" class="headerlink" title="5.3 MapReduce架构概述"></a>5.3 MapReduce架构概述</h4><h3 id="6-大数据技术生态体系"><a href="#6-大数据技术生态体系" class="headerlink" title="6. 大数据技术生态体系"></a>6. 大数据技术生态体系</h3><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200726100836955.png" alt="image-20200726100836955"></p><p><strong>小结：</strong>大概描述就是 首先 大数据的根本就是分析计算数据，那一定要定位数据来源，数据来源大体包含三个方面，分别是 正规的数据库（结构化数据），其次还有文件日志（半结构化数据）以及通过一些爬虫手段获取的互联网数据（非结构化数据）这就组成了我们的**<em>数据来源层**</em>。 </p><p>​        有了数据来源接下来就需要将这些数据传输到我们的分布式文件存储系统（HDFS）或者直接通过消息队列（kafka）将数据传输到数据计算层来做数据分析和运算，这里我们把专门做数据传输的技术层称之为*<strong>数据传输层***，同时保存到HDFS中后，我们成这块内容为 *</strong>数据存储层***。</p><p>​        有了具体的数据那后续就可以做数据分析运算了，这时候就要有 <strong><em>数据计算层</em></strong> 来完成，这部分大概根据数据结果的实效性可以分为两类数据分析运算的场景，一种是离线运算，一种实时运算，离线的话我们通常采用MapReduce和Hive来完成。实时的话就会用到Spark体系架构完成或者用Fink框架。</p><p>​        结合上面提到的概念，我们还要加入 <strong><em>资源管理层</em></strong>   主要有 YARN 来完成，它的主要工作就是来分配调度计算资源的，用来协作 MapReduce 作业。同时在实行数据运算的时候 我们考虑到服务器的资源分配以及人物先后执行的顺序，有加入了一个 <strong><em>任务调度层</em></strong>  专门来控制运算作业的执行时间和先后顺序</p><p>​        以上就是大数据架构体系的协作规则和架构说明，但是我们最后又考虑到 分布式集群的操作，各个版块和服务一定会交叉协同工作，所以最后利用Zookeeper来统一管理 分布式集群架构。OK，以上就是关于大数据技术生态体系的话术表现。</p><p>​        </p><h3 id="7-推荐系统框架图"><a href="#7-推荐系统框架图" class="headerlink" title="7. 推荐系统框架图"></a>7. 推荐系统框架图</h3><img src="Hadoop笔记总结-01.assets/image-20200729111555275.png" alt="image-20200729111555275" style="zoom: 50%;" /><p><strong>小结：</strong>以上的一个推荐系统的大概描述，首先一定从用户的行为开始入手，当用户购买一件商品加入购物车后，我们往往会给用户推荐相关的类似产品或者连带产品，这是目前电商系统很常见的一种营销手段。这个推荐的数据是如何产生的呢？</p><p>1.用户将商品加入购物车，这是会产生购物车数据，这就是我们的数据来源</p><p>2.利用数据传输层的相关技术将数据进行搜集处理然后通过Kafak消息队列直接将数据传输到 实时运算的框架中进行分析运算。</p><p>3.当 数据计算层 把数据分析运算后会得到最终的结果，根据结果为依据找到相关的类似商品的数据进行整合。</p><p>4.最后回到电商系统中 的推荐模块 通过调用接口的方式获取最终的分析处理后整合的商品数据的结果，将其展示到客户端页面中。</p><p>上面大概就是一个推荐的流程，你学到了吗！！！</p><h2 id="三、Hadoop运行环境搭建（重点）"><a href="#三、Hadoop运行环境搭建（重点）" class="headerlink" title="三、Hadoop运行环境搭建（重点）"></a>三、Hadoop运行环境搭建（重点）</h2><h3 id="1-虚拟机环境准备"><a href="#1-虚拟机环境准备" class="headerlink" title="1. 虚拟机环境准备"></a>1. 虚拟机环境准备</h3><ul><li><p><strong>1). 准备模板机</strong>（安装最小化的Linux系统）</p><ul><li><p>yum安装必要的插件</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install -y epel-release</span><br><span class="line"></span><br><span class="line">sudo yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git</span><br></pre></td></tr></table></figure></li><li><p>修改 /etc/hosts 文件</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">192.168.2.100 hadoop100</span><br><span class="line">192.168.2.101 hadoop101</span><br><span class="line">192.168.2.102 hadoop102</span><br><span class="line">192.168.2.103 hadoop103</span><br><span class="line">192.168.2.104 hadoop104</span><br><span class="line">192.168.2.105 hadoop105</span><br><span class="line">192.168.2.106 hadoop106</span><br><span class="line">192.168.2.107 hadoop107</span><br><span class="line">192.168.2.108 hadoop108</span><br></pre></td></tr></table></figure></li><li><p>设置Linux的防火墙开机不自启</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure></li><li><p>创建 atguigu 用户</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">useradd atguigu</span><br></pre></td></tr></table></figure></li><li><p>修改/etc/sudoers文件 配置atguigu用户具有root权限</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">在第92行的位置加上以下内容</span><br><span class="line">atguigu ALL&#x3D;(ALL)  NOPASSWD:ALL</span><br><span class="line"></span><br><span class="line">:wq! 强制保存退出。</span><br></pre></td></tr></table></figure></li><li><p>在/opt目录下创建两个文件夹 </p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir &#x2F;opt&#x2F;software   --放置需要安装的软件的安装包</span><br><span class="line">madir &#x2F;opt&#x2F;module     --软件的安装目录</span><br></pre></td></tr></table></figure></li><li><p>配置 两个文件夹 属于 atguigu 用户和 atguigu 组</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chown atguigu:atguigu &#x2F;opt&#x2F;software</span><br><span class="line"></span><br><span class="line">chown atguigu:atguigu &#x2F;opt&#x2F;module</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>2). 准备开发用的虚拟机</strong></p><ul><li><p>根据模板机克隆一台机器</p><ul><li> 根据克隆的步骤进行克隆就可以(参考Linux阶段的克隆操作)</li><li> 启动虚拟机</li></ul></li><li><p>修改克隆机的主机名</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.编辑hostname文件</span><br><span class="line">vim &#x2F;etc&#x2F;hostname</span><br><span class="line"></span><br><span class="line">2.修改主机名称</span><br><span class="line">hadoop101</span><br><span class="line"></span><br><span class="line">3.重启机器 </span><br><span class="line">reboot</span><br></pre></td></tr></table></figure></li><li><p>修改克隆机的ip</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.编辑ifcfg-ens33文件</span><br><span class="line">vim &#x2F;etc&#x2F;sysconfig&#x2F;network-spcripts&#x2F;ifcfg-ens33</span><br><span class="line"></span><br><span class="line">2.重点修改的一下标注的地方</span><br></pre></td></tr></table></figure><p> <img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200729142023446.png" alt="image-20200729142023446"></p></li><li><p>利用FinallShell工具连接Linux</p><p> <img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200729142145665.png" alt="image-20200729142145665"></p></li></ul></li></ul><h3 id="2-在准备好开发机hadoop101安装JDK"><a href="#2-在准备好开发机hadoop101安装JDK" class="headerlink" title="2. 在准备好开发机hadoop101安装JDK"></a>2. 在准备好开发机hadoop101安装JDK</h3><p>​     <strong>概述：</strong>本小节主要讲解在Linux中如何安装jdk，首先要明白Hadoop是用Java开发的，换言之Hadoop就是一款Java写的软件，那么想要运行Hadoop必然需要jdk环境。在Linux中安装Jdk和Windows中安装原理相同，只不过在Linux中Jdk的体现形式是一个 tar.gz的压缩包而Windows中是一个可视化安装程序。</p><ul><li><p><strong>1). 卸载现有JDK</strong></p><p> ​    <strong>注意：如果首次安装就没必要进行这一步，如果想更换jdk,非首次安装则需要先把已有的卸载掉</strong></p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps</span><br></pre></td></tr></table></figure></li><li><p><strong>2). 将jdk的tar包导入到Linux中opt目录下的software下</strong></p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">在我们的FinallShell工具中，直接找到opt目录下的software文件夹，将Windows目录下的jdk-8u212-linux-x64.tar.gz 包拖拽到software文件夹里即可</span><br></pre></td></tr></table></figure></li><li><p><strong>3).解压jdk压缩包到opt目录下的module文件夹中</strong></p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -zxvf jdk-8u212-linux-x64.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure></li><li><p><strong>4). 配置jdk的环境变量</strong></p><p> <strong>概述：</strong>接下来我们就要配置jdk的环境变量，思路和在windows系统下配置环境变量类似。这里注意一下，在Linux中 我们可以通过修改 Linux的核心profile文件来添加jdk的环境变量，但是我们通常不会这么做，原因就是不希望改动Linux原有的核心文件，以免引起不必要的麻烦，那我们怎么做呢？推荐方式就是自己在指定的目录下创建一个xxx.sh文件用来充当我们自己的配置文件。当Linux系统启动后会加载profile 文件，而profile文件中的脚本会循环遍历加载 /etc/profile.d/ 目录下所有以sh为后缀名的文件，所以我们自己创建xxx.sh文件也就被加载到了。固然环境变量也就生效了！</p><ul><li><p>在/etc/profile.d/目录下新建文件 my_env.sh文件</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh</span><br></pre></td></tr></table></figure></li><li><p>在my_env.sh文件中添加一下内容</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#JAVA_HOME</span><br><span class="line">export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_212</span><br><span class="line">export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin</span><br></pre></td></tr></table></figure></li><li><p>保存后退出</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">:wq</span><br></pre></td></tr></table></figure></li><li><p>source 重新加载 /etc/profile文件，环境变量生效</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure></li><li><p>验证jdk是否安装以及配置成功</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure><p> 如下图就成功了！</p> <img src="Hadoop笔记总结-01.assets/image-20200729231158594.png" alt="image-20200729231158594" style="zoom:80%;" /><p> 如果没成功就reboot重启Linux，如果没问题就不用了重启！</p></li></ul></li></ul><h3 id="3-在开发机hadoop101安装Hadoop"><a href="#3-在开发机hadoop101安装Hadoop" class="headerlink" title="3. 在开发机hadoop101安装Hadoop"></a>3. 在开发机hadoop101安装Hadoop</h3><p><strong>概述：</strong>终于要安装hadoop了，hadoop我们把它看做适合jdk是同一类型的软件，jdk怎么操作hadoop也怎么操作就可以！</p><ul><li><p> <strong>1). 将hadoop的tar包拖拽到/opt/software目录下</strong></p></li><li><p><strong>2). 将hadoop解压缩到/opt/module目录下</strong></p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -zxvf hadoop-3.1.3.tar.gz -C &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure></li><li><p><strong>3).配置hadoop的环境变量</strong></p><p> <strong>注意：</strong>hadoop中有一个特别之处，就是在hadoop的目录下的bin目录和sbin目录都是hadoop的执行脚本，所以我们在配置hadoop的环境变量的时候要注意把这两个都配上才可以！剩下其他的操作都和jdk一样了！</p><ul><li><p>打开/etc/profile.d/my_env.sh文件</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh</span><br></pre></td></tr></table></figure></li><li><p>在my_env.sh文件末尾添加如下内容：（shift+g）</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#HADOOP_HOME</span><br><span class="line">export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3</span><br><span class="line">export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin</span><br><span class="line">export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;sbin</span><br></pre></td></tr></table></figure></li><li><p>保存退出</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">:wq</span><br></pre></td></tr></table></figure></li><li><p>source 重新加载 /etc/profile文件，环境变量生效</p> <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source &#x2F;etc&#x2F;profile</span><br></pre></td></tr></table></figure></li><li><p>验证hadoop是否安装以及配置成功</p> <figure class="highlight markdown"><table><tr><td class="code"><pre><span class="line">hadoop version</span><br></pre></td></tr></table></figure><p> <img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200730000725426.png" alt="image-20200730000725426"></p><p> 如图所示表示安装成功！</p></li></ul></li></ul><h3 id="4-Hadoop目录结构"><a href="#4-Hadoop目录结构" class="headerlink" title="4. Hadoop目录结构"></a>4. Hadoop目录结构</h3><ul><li> <strong>bin：</strong> bin目录是Hadoop最基本的管理脚本和使用脚本所在的目录，这些脚本是sbin目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用Hadoop</li><li> <strong>etc：</strong> Hadoop配置文件所在的目录，包括：core-site.xml、hdfs-site.xml、mapred-site.xml和yarn-site.xml等配置文件。</li><li> <strong>include：</strong>对外提供的编程库头文件（具体的动态库和静态库在lib目录中），这些文件都是用C++定义的，通常用于C++程序访问HDFS或者编写MapReduce程序。</li><li> <strong>lib：</strong>包含了Hadoop对外提供的编程动态库和静态库，与include目录中的头文件结合使用。</li><li> <strong>libexec：</strong>各个服务对应的shell配置文件所在的目录，可用于配置日志输出目录、启动参数（比如JVM参数）等基本信息。</li><li> <strong>sbin：</strong> Hadoop管理脚本所在目录，主要包含HDFS和YARN中各类服务启动/关闭的脚本。</li><li> <strong>share：</strong> Hadoop各个模块编译后的Jar包所在目录，这个目录中也包含了Hadoop文档。</li></ul><h2 id="四、Hadoop运行模式"><a href="#四、Hadoop运行模式" class="headerlink" title="四、Hadoop运行模式"></a>四、Hadoop运行模式</h2><p><strong>前言：</strong>本章节主要来学习Hadoop的运行模式，何谓运行模式呢？简单的讲就是Hadoop该如何运作起来，或者理解为玩Hadoop的游戏规则，是单台机器运行，还是多台协作运行，不同的运行模式有不一样的配置和处理。Hadoop中一共存在三种运行模式， 本地模式、伪分布式模式、完全分布式模式。</p><p><strong>本地模式：</strong>在一台单机上运行，没有分布式文件系统，而是直接读写本地操作系统的文件系统。</p><p><strong>伪分布式：</strong>这种模式也是在一台单机上运行，但用不同的Java进程模仿分布式运行中的各类结点: (NameNode,DataNode,JobTracker,TaskTracker,SecondaryNameNode) ，同理 集群中的结点由一个JobTracker和若干个TaskTracker组成，JobTracker负责任务的调度，TaskTracker负责并行执行任务。TaskTracker必须运行在DataNode上，这样便于数据的本地计算。JobTracker和NameNode则无须在同一台机器上。一个机器上，既当namenode，又当datanode,或者说 既 是jobtracker,又是tasktracker。没有所谓的在多台机器上进行真正的分布式计算，故称为”伪分布式”。</p><p><strong>完全分布式：</strong>真正的分布式，由3个及以上的实体机或者虚拟机组件的机群。</p><p><strong>注意：</strong>我们在课程中 用本地模式来入门开胃，然后集中火力做 <strong>完全分布式</strong> 伪分布式只做了解即可，没有太大意义！</p><h3 id="1-本地运行模式"><a href="#1-本地运行模式" class="headerlink" title="1.本地运行模式"></a>1.本地运行模式</h3><p>​    本小节主要就是感受一把Hadoop的运行过程，根据Hadoop官方提供的示例来操作几个Hadoop的基本功能点。更重要的是掌握基本操作Hadoop的步骤和思路。</p><p><strong>案例1需求描述：</strong>利用hadoop的grep过滤功能，将一批文件中的一些内容过滤出来。</p><p><strong>实现步骤：</strong></p><p><strong>1.1 在hadoop的解压目录创建一个文件夹input，作为需要过滤的文件的输入目录</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir input</span><br></pre></td></tr></table></figure><p>*<em>1.2 将hadoop目录下的 etc/hadoop/</em>.xml文件都复制到 input目录下，作为被过滤文件**</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp &#x2F;etc&#x2F;hadoop&#x2F;*.xml input</span><br></pre></td></tr></table></figure><p><strong>1.3 执行 bin/hadoop 命令，运行share/hadoop/mapreduce/目录下的hadoop-mapreduce-examples-3.1.3.jar包中的 grep 过滤功能，并限制一定的规则</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin&#x2F;hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.3.jar grep input output &#39;dfs[a-z.]+&#39;</span><br></pre></td></tr></table></figure><p><strong>1.4 最后在output目录下查看过滤的结果即可！</strong></p><p><strong>案例2需求描述：</strong>利用Hadoop完成经典wordcount(单词统计)，就是针对一些文件计算统计里面相同单词的个数。</p><p><strong>实现步骤：</strong></p><p><strong>1.1 创建在hadoop-3.1.3文件下面创建一个wcinput文件夹</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir wcinput</span><br></pre></td></tr></table></figure><p><strong>1.2 在wcinput文件下创建一个word.txt文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd wcinput</span><br></pre></td></tr></table></figure><p><strong>1.3 编辑word.txt文件</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim word.txt</span><br><span class="line"></span><br><span class="line">在文件中输入如下内容(内容随意)</span><br><span class="line">hadoop yarn</span><br><span class="line">hadoop mapreduce</span><br><span class="line">atguigu</span><br><span class="line">atguigu</span><br></pre></td></tr></table></figure><p><strong>1.4 回到Hadoop目录/opt/module/hadoop-3.1.3</strong>  <strong>执行程序</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput</span><br></pre></td></tr></table></figure><p><strong>1.5 查看结果</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> cat wcoutput&#x2F;part-r-00000</span><br><span class="line"> </span><br><span class="line">看到如下结果：</span><br><span class="line">atguigu 2</span><br><span class="line">hadoop  2</span><br><span class="line">mapreduce 1</span><br><span class="line">yarn    1</span><br></pre></td></tr></table></figure><h3 id="2-完全分布式运行模式-重点掌握"><a href="#2-完全分布式运行模式-重点掌握" class="headerlink" title="2.完全分布式运行模式(重点掌握)"></a>2.完全分布式运行模式(重点掌握)</h3><p>​    本章节是重中之重，主要讲解完全分布式运行模式。</p><h4 id="2-1-准备3台服务器"><a href="#2-1-准备3台服务器" class="headerlink" title="2.1 准备3台服务器"></a>2.1 准备3台服务器</h4><p>为了满足集群的环境，我们需要准备三台服务器，准备方式就是根据我们之前做好的模板机进行克隆即可，但是需要注意，三台服务器的的 静态ip地址和主机名都要修改一下，以便区分！</p><h5 id="2-1-1-克隆第一台"><a href="#2-1-1-克隆第一台" class="headerlink" title="2.1.1 克隆第一台"></a>2.1.1 克隆第一台</h5><p>修改主机名为hadoop102</p><p>修改ip地址为：192.168.2.102</p><h5 id="2-1-2-克隆第二台"><a href="#2-1-2-克隆第二台" class="headerlink" title="2.1.2 克隆第二台"></a>2.1.2 克隆第二台</h5><p>修改主机名为hadoop103</p><p>修改ip地址为：192.168.2.103</p><h5 id="2-1-3-克隆第三台"><a href="#2-1-3-克隆第三台" class="headerlink" title="2.1.3 克隆第三台"></a>2.1.3 克隆第三台</h5><p>修改主机名为hadoop104</p><p>修改ip地址为：192.168.2.104</p><h4 id="2-2-集群分发脚本的应用场景"><a href="#2-2-集群分发脚本的应用场景" class="headerlink" title="2.2 集群分发脚本的应用场景"></a>2.2 集群分发脚本的应用场景</h4><p><strong>场景介绍：</strong></p><p>​        上面我们已经准备好了三台服务器，并且都各自修改了主机名和ip地址。但是我们知道 需要额必备软件以及环境变量还没有配置，如果机械的一台一台配置也可以但是这样会引发大量的重复性工作，没有必要。如何能避免重复配置呢，最好是值在一台机器进行修改 然后将修改的配置信息同步到集群的所有机器那就完美了！这时候就要用到 分发脚本 的方案！</p><h5 id="2-2-1-scp-安全拷贝"><a href="#2-2-1-scp-安全拷贝" class="headerlink" title="2.2.1 scp 安全拷贝"></a>2.2.1 scp 安全拷贝</h5><p><strong>scp含义：</strong></p><p>​    scp命令可以实现服务器与服务器之间的数据拷贝</p><p><strong>基本语法：</strong></p><p>​    scp      -r          $pdir/$fname                 $user@hadoop$host:$pdir/$fname</p><p>​    命令  递归    要拷贝的文件路径/名称   目的用户@主机:目的路径/名称</p><p><strong>案例实操：</strong></p><p>前提：在 hadoop102 hadoop103 hadoop104 都已经创建好的 /opt/module</p><p>​      /opt/software 两个目录， 并且已经把这两个目录修改为atguigu:atguigu</p><p>​      sudo chown atguigu:atguigu -R /opt/module</p><p>1).在hadoop101上，将hadoop101中/opt/module/目录下所有内容拷贝到hadoop102上的/opt/module/目录下。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r &#x2F;opt&#x2F;module&#x2F;* atguigu@hadoop102:&#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure><p>2).在hadoop103上，将hadoop101中/opt/module/目录下的所有内容拷贝到hadoop103的/opt/module/目录下。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r atguigu@hadoop101:&#x2F;opt&#x2F;module&#x2F;* &#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure><p>3).在hadoop103上，将hadoop101中/opt/module/目录下的所有内容拷贝到hadoop104的/opt/module/目录下。</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp -r atguigu@hadoop101:&#x2F;opt&#x2F;module&#x2F;* atguigu@hadoop104:&#x2F;opt&#x2F;module&#x2F;</span><br></pre></td></tr></table></figure><p>4).在任意一台机器上，将hadoop101中的/etc/profile.d目录下的my_env.sh配置文件分别复制到hadoop102、hadoop103、hadoop104上</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. scp -r &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh root@hadoop102:&#x2F;etc&#x2F;profile.d&#x2F;</span><br><span class="line">2. scp -r &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh root@hadoop103:&#x2F;etc&#x2F;profile.d&#x2F;</span><br><span class="line">3. scp -r &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh root@hadoop104:&#x2F;etc&#x2F;profile.d&#x2F;</span><br></pre></td></tr></table></figure><h5 id="2-2-2-rsync远程同步工具"><a href="#2-2-2-rsync远程同步工具" class="headerlink" title="2.2.2 rsync远程同步工具"></a>2.2.2 rsync远程同步工具</h5><p><strong>功能描述：</strong></p><p>​        rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p><p><strong>rsync和scp区别：</strong></p><p>​        用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</p><p><strong>基本语法：</strong></p><p>rsync   -av    $pdir/$fname        $user@hadoop$host:$pdir/$fname</p><p>命令  选项参数  要拷贝的文件路径/名称  目的用户@主机:目的路径/名称</p><p>​     选项参数说明</p><table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-a</td><td>归档拷贝</td></tr><tr><td>-v</td><td>显示复制过程</td></tr></tbody></table><p><strong>案例实操:</strong></p><p>把hadoop102机器上的/opt/software目录同步到hadoop103服务器的/opt/software目录下（没有实际意义的操作只是为了练手）</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -av &#x2F;opt&#x2F;software&#x2F;* atguigu@hadoop103:&#x2F;opt&#x2F;software&#x2F;</span><br></pre></td></tr></table></figure><h5 id="2-2-3-分发脚本的应用"><a href="#2-2-3-分发脚本的应用" class="headerlink" title="2.2.3 分发脚本的应用"></a>2.2.3 分发脚本的应用</h5><p><strong>概述：</strong>前面其实我们已经是实现了服务器之间的文件目录拷贝传递了，但是每次都得执行命令来实现，还是比较麻烦的，干脆一步到位，通过编写一个脚本 通过执行脚本来实现信息拷贝。</p><p><strong>前提：</strong> 在/home/atguigu/bin这个目录下存放的脚本，atguigu用户可以在系统任何地方直接执行。</p><p><strong>脚本实现：</strong></p><p>1). 在/home/atguigu/bin目录下创建xsync文件</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 opt]$ cd &#x2F;home&#x2F;atguigu</span><br><span class="line">[atguigu@hadoop102 ~]$ mkdir bin</span><br><span class="line">[atguigu@hadoop102 ~]$ cd bin</span><br><span class="line">[atguigu@hadoop102 bin]$ vim xsync</span><br></pre></td></tr></table></figure><p>2). 在该文件中编写如下代码</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash">1. 判断参数个数</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">  echo Not Enough Arguement!</span><br><span class="line">  exit;</span><br><span class="line">fi</span><br><span class="line"><span class="meta">#</span><span class="bash">2. 遍历集群所有机器</span></span><br><span class="line">for host in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">  echo ====================  $host  ====================</span><br><span class="line"><span class="meta">  #</span><span class="bash">3. 遍历所有目录，挨个发送</span></span><br><span class="line">  for file in $@</span><br><span class="line">  do</span><br><span class="line">    #4. 判断文件是否存在</span><br><span class="line">    if [ -e $file ]</span><br><span class="line">    then</span><br><span class="line">      #5. 获取父目录</span><br><span class="line">      pdir=$(cd -P $(dirname $file); pwd)</span><br><span class="line">      #6. 获取当前文件的名称</span><br><span class="line">      fname=$(basename $file)</span><br><span class="line">      ssh $host &quot;mkdir -p $pdir&quot;</span><br><span class="line">      rsync -av $pdir/$fname $host:$pdir</span><br><span class="line">    else</span><br><span class="line">      echo $file does not exists!</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">done</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>3). 修改文件的执行权限</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod 777 xsync</span><br></pre></td></tr></table></figure><p>4). 将脚本复制到/bin中，以便全局调用</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo cp xsync &#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><p>5). 测试脚本</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xsync test.txt</span><br></pre></td></tr></table></figure><h4 id="2-3-分布式集群规划"><a href="#2-3-分布式集群规划" class="headerlink" title="2.3 分布式集群规划"></a>2.3 分布式集群规划</h4><p>​    <strong>概述：</strong>接下来我们就要搭建Hadoop集群了，在操作之前一定要有具体的集群规划，集群规划其实就是把Hadoop中的核心组件如何安排到每台机器上。</p><p>​    <strong>分析：</strong> 通过前面的介绍我们知道 在Hadoop集群当中先要考虑数据的存储以及资源调度的安排。那就会涉及到NameNode 、ResourceManager 、SecondaryNameNode 、DataNode 、 NodeManager。如何把这些组件分布到每一台机器上，就得合理分析一下。</p><p>NameNode 、ResourceManager 、SecondaryNameNode 这三个组件相对来说比较耗费资源，我们通常把他们分布到不同的机器上。所以三台机器每一台分布一个。</p><p>DataNode是具体存储数据的，因为三台机器都具备存储空间，那每一台都分布一个DataNode</p><p>NodeManager是负责每一台机器的资源的管理，因此三台机器每一台也分布一个NodeManager</p><p><strong>hadoop102            NameNode                         DataNode              NodeManager</strong></p><p><strong>hadoop103            ResourceManager              DataNode              NodeManager</strong></p><p><strong>hadoop104            SecondaryNameNode      DataNode                NodeManager</strong></p><h4 id="2-4-搭建完全集群"><a href="#2-4-搭建完全集群" class="headerlink" title="2.4 搭建完全集群"></a>2.4 搭建完全集群</h4><h5 id="1-先删除每个节点中hadoop安装目录下的-data-和-logs目录，如果是最新解压配置的hadoop集群，并没有这两个目录就不需要进行删除这步。"><a href="#1-先删除每个节点中hadoop安装目录下的-data-和-logs目录，如果是最新解压配置的hadoop集群，并没有这两个目录就不需要进行删除这步。" class="headerlink" title="1.先删除每个节点中hadoop安装目录下的 data 和 logs目录，如果是最新解压配置的hadoop集群，并没有这两个目录就不需要进行删除这步。"></a><strong>1.先删除每个节点中hadoop安装目录下的 data 和 logs目录，如果是最新解压配置的hadoop集群，并没有这两个目录就不需要进行删除这步。</strong></h5><h5 id="2-在hadoop-env-sh文件中，配置JAVA-HOME-的环境变量，这是因为Hadoop运行的时候需要java的环境变量。"><a href="#2-在hadoop-env-sh文件中，配置JAVA-HOME-的环境变量，这是因为Hadoop运行的时候需要java的环境变量。" class="headerlink" title="2.在hadoop-env.sh文件中，配置JAVA_HOME 的环境变量，这是因为Hadoop运行的时候需要java的环境变量。"></a><strong>2.在hadoop-env.sh文件中，配置JAVA_HOME 的环境变量，这是因为Hadoop运行的时候需要java的环境变量。</strong></h5><h5 id="3-配置Hadoop的4大核心配置文件"><a href="#3-配置Hadoop的4大核心配置文件" class="headerlink" title="3.配置Hadoop的4大核心配置文件"></a><strong>3.配置Hadoop的4大核心配置文件</strong></h5><ul><li><p><strong>core-site.xml</strong>  这个是hadoop总的核心配置文件，集群加载启动的时候首先会加载解析此配置文件，具体配置内容如下：</p> <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--cmeNode的地址 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 指定hadoop数据的存储目录 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/module/hadoop-3.1.3/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.hosts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理用户所属组 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.groups<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置该atguigu(superUser)允许通过代理的用户--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.proxyuser.atguigu.users<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">   </span><br></pre></td></tr></table></figure></li><li><p><strong>hdfs-site.xml</strong> 这个是hdfs的核心配置文件，具体配置内容如下：</p> <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"> <span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"> <span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"> <span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">   Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--指定NameNode数据的存储目录--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.data.dir&#125;/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--指定DataNode数据的存储目录--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.data.dir&#125;/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--指定SecondaryNameNode数据的存储目录--&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file://$&#123;hadoop.data.dir&#125;/namesecondary<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- nn web端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:9870<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 2nn web端访问地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop104:9868<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>yarn-site.xml 这个是Yarn的核心配置文件,具体内容如下：</p> <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 指定MR走shuffle --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定ResourceManager的地址--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop103<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 环境变量的继承 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span>                         <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- yarn容器允许分配的最大最小内存 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- yarn容器允许管理的物理内存大小 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4096<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 关闭yarn对物理内存和虚拟内存的限制检查 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure></li><li><p>mapred-site.xml  这是MapReduce配置文件，配置内容如下：</p> <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="4-启动HDFS，单独启动每一台机器上的组件（重点）"><a href="#4-启动HDFS，单独启动每一台机器上的组件（重点）" class="headerlink" title="4. 启动HDFS，单独启动每一台机器上的组件（重点）"></a><strong>4. 启动HDFS，单独启动每一台机器上的组件（重点）</strong></h5></li><li><ol><li><p>因为hdfs分布式文件系统本质是一个文件系统，固然在使用之前要进行格式化，那么在哪台机器格式化呢，就是hdfs的大哥NameNode所在的节点进行格式化，格式化命令如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ hdfs namenode -format</span><br></pre></td></tr></table></figure></li></ol></li><li><ol start="2"><li>启动HDFS文件系统，注意：我们现在是每台机器逐个启动所以一定要清晰之前定的集群规划的方案，现在要启动HDFS文件系统，而HDFS系统又包含 NameNode、SecondaryNameNode、DataNode，这三大组件有分别被规划在 NameNode在hadoop102、SecondaryNameNode在hadoop104、以及每一台机器上都有DataNode，所以启动流程如下：</li></ol><ul><li><p>在hadoop102上 启动NameNode 命令如下：</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ hdfs --daemon start namenode</span><br></pre></td></tr></table></figure></li><li><p>在hadoop104上 启动SecondaryNameNode 命令如下：</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop104 ~]$ hdfs --daemon start secondarynamenode</span><br></pre></td></tr></table></figure></li><li><p>在hadoop102 hadoop103 hadoop104 都启动DataNode 命令如下：</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ hdfs --daemon start datanode</span><br><span class="line">[atguigu@hadoop103 hadoop]$ hdfs --daemon start namenode</span><br><span class="line">[atguigu@hadoop104 hadoop]$ hdfs --daemon start namenode</span><br></pre></td></tr></table></figure></li></ul></li><li><ol start="3"><li>检测hdfs是否启动成功 Web端查看HDFS的NameNode</li></ol></li></ul><p>（a）浏览器中输入：<a href="http://hadoop102:9870/">http://hadoop102:9870</a></p><p>（b）查看HDFS上存储的数据信息</p><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200821105319878.png" alt="image-20200821105319878"></p><h5 id="5-启动Yarn"><a href="#5-启动Yarn" class="headerlink" title="5. 启动Yarn"></a><strong>5. 启动Yarn</strong></h5><p>​        根据集群规划，Yarn的ResourceManager我们分布在hadoop103上，NodeManager每一台机器上都存在所以启动流程如下：</p><ul><li><p>1). 在hadoop103 启动resourcemanager 命令如下：</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop103 hadoop]$ yarn --daemon start resourcemanager</span><br></pre></td></tr></table></figure></li><li><p>2). 分别在hadoop102、hadoop103、hadoop104 启动nodemanager 命令如下：</p> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ hdfs --daemon start nodemanager</span><br><span class="line">[atguigu@hadoop103 hadoop]$ hdfs --daemon start nodemanager</span><br><span class="line">[atguigu@hadoop104 hadoop]$ hdfs --daemon start nodemanager</span><br></pre></td></tr></table></figure></li><li><p>3). 检测Yarn是否启动成功 Web端查看YARN的ResourceManager</p><p> （a）浏览器中输入：<a href="http://hadoop103:8088/">http://hadoop103:8088</a></p><p> （b）查看YARN上运行的Job信息</p><p> <img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200821110928665.png" alt="image-20200821110928665"></p></li></ul><h5 id="6-简单测试使用集群"><a href="#6-简单测试使用集群" class="headerlink" title="6.简单测试使用集群"></a>6.简单测试使用集群</h5><p>​    <strong>前言：</strong> 接下来简单测试试用一下我们搭建好的集群环境，操作的目标就是在HDFS 文件系统上上传文件以及运行一下简单的MapReduce程序即可！但是这里需要我们注意的一个 <strong>问题就是 HDFS系统所指向的物理路径究竟是哪 一会应该往哪个路径下上传文件！</strong></p><p>​    <strong>问题一：HDFS文件系统怎么定位？</strong></p><p>​    首先我们清楚，当前集群是运行在Linux上的，而Linux又是在Windows系统中的通过虚拟机的方式运行的，所以HDFS文件系统本质上也是占用了我们当前电脑硬盘的一部分，通过hadoop体系为HDFS分配出的一块存储空间。但是一定要注意它具有独立性，是由Hadoop独立来管理的。</p><p>​    <strong>问题二：在操作HDFS文件系统的时候如何理解它的输入路径和输出路径？</strong></p><p>​    Hadoop如何识别是Linux路径还是HDFS路径呢？本质上还得看 Hadoop的核心配置文件的fs.defaultFS的配置信息。</p><p>当前我们搭建的集群配置如下：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://hadoop102:9820<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>参考官网默认配置如下：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>对比分析：</strong></p><p>1). Hadoop的fs.defaultFS的默认配置是file:///  如果解析的是这个配置，file:/// 本质上所表示的就是Linux本地路径，那么在操作中写输入输出就按照Linux的规则正常写就行，例如编写执行wordcount程序的命令如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ hadoop jar share/hadoop/mapredece/hadoop-mapreduce-ecanples.jar wordcount wcinput/wc.input wcoutput</span><br></pre></td></tr></table></figure><p>2). 如果我们自己修改了core-site.xml 核心配置文件配置 fs.defaultFS 的值为hdfs://hadoop102:9820 那么意味着在解析输入输出路径的时候指向的是HDFS系统维护的目录结构 在HDFS系统底层维护的路径是  <strong>/user/atguigu/wcinput</strong> 所以如果是在这个情况下我们要操作wordcount程序就应该这么写了 命令如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ hadoop jar share/hadoop/mapredece/hadoop-mapreduce-ecanples.jar wordcount /user/atguigu/wcinput/wc.input /user/atguigu/wcoutput</span><br></pre></td></tr></table></figure><p><strong>OK! 有了上面的内容作为支撑，下面我们就正式对Hadoop集群进行简单测试操作！！！</strong></p><h6 id="6-1-在HDFS中创建一个目录-user-atguigu-input-目录"><a href="#6-1-在HDFS中创建一个目录-user-atguigu-input-目录" class="headerlink" title="6.1 在HDFS中创建一个目录 /user/atguigu/input 目录"></a>6.1 在HDFS中创建一个目录 /user/atguigu/input 目录</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hdfs dfs -rm -R /user/atguigu/input</span><br></pre></td></tr></table></figure><h6 id="6-2-将hadoop安装目下的wcinput-wc-input-文件上传到HDFS文件系统上的-user-atguigu-input-目录下"><a href="#6-2-将hadoop安装目下的wcinput-wc-input-文件上传到HDFS文件系统上的-user-atguigu-input-目录下" class="headerlink" title="6.2 将hadoop安装目下的wcinput/wc.input 文件上传到HDFS文件系统上的 /user/atguigu/input 目录下"></a>6.2 将hadoop安装目下的wcinput/wc.input 文件上传到HDFS文件系统上的 /user/atguigu/input 目录下</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hdfs dfs -put wciput/wc.input /user/atguigu/input</span><br></pre></td></tr></table></figure><h6 id="6-3-如何在HDFS上查看具体存储的文件"><a href="#6-3-如何在HDFS上查看具体存储的文件" class="headerlink" title="6.3 如何在HDFS上查看具体存储的文件"></a>6.3 如何在HDFS上查看具体存储的文件</h6><p>DataNode的存储目录：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop103 hadoop-3.1.3]$ cd data/data/current/BP-1528516923-192.168.2.102-1597943910514/current/finalized/subdir0/subdir0/</span><br></pre></td></tr></table></figure><h6 id="6-4-测试Yarn是否能正常使用-还是以Mapreduce的wordcount程序为例"><a href="#6-4-测试Yarn是否能正常使用-还是以Mapreduce的wordcount程序为例" class="headerlink" title="6.4 测试Yarn是否能正常使用 还是以Mapreduce的wordcount程序为例"></a>6.4 测试Yarn是否能正常使用 还是以Mapreduce的wordcount程序为例</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop104 hadoop-3.1.3]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /user/atguigu/input /user/atguigu/output</span><br></pre></td></tr></table></figure><p>6.5 在hdfs上面查看执行后的结果</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ hdfs dfs -cat /user/atguigu/output/part-r-00000</span><br></pre></td></tr></table></figure><h5 id="7-SSH免密登录"><a href="#7-SSH免密登录" class="headerlink" title="7. SSH免密登录"></a>7. SSH免密登录</h5><p><strong>存在的问题：</strong> 集群启动和关闭，目前我们都是通过单点操作完成的，这样很不方便，于是就考虑能不能在一台机器上就能搞定集群的启动和关闭？</p><p><strong>分析：</strong></p><p>参照之前的脚本分发的思路，我们可以编写一个集群启动和关闭的脚本，就是把哪些在每一台机器上输入的命令封装到一个脚本中，然后通过执行脚本来实现集群启动关闭的目的。</p><p><strong>脚本的大概思路：</strong></p><p>​    登录到hadoop102  启动/关闭 namenode</p><p>​    登录到hadoop104  启动/关闭 secondarynamenode</p><p>​    登录到hadoop102   hadoop103   hadoop104  启动/关闭 datanode</p><p>​    登录到hadoop103 启动/关闭 resourcemanager </p><p>​    登录到hadoop102 hadoop103 hadoop104  启动/关闭 nodemanager</p><p><strong>如何登录远程的机器：</strong></p><p>语法：ssh ip/主机名 </p><p><strong>无密钥配置：</strong> 单纯的 ssh 命令操作，虽然可以只在一台机器操作了但是操作步骤较多，而且登录的时候每次都需要输入密码，我们接下来要做到免密登录+脚本控制</p><p><strong>免密登录的原理：</strong></p><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200823002113546.png" alt="image-20200823002113546"></p><p><strong>实现步骤：</strong></p><p>1). 生成公钥和私钥：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 .ssh]$ ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><p>然后敲（四次回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p><p>2). 将公钥拷贝到要免密登录的目标机器上</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop102</span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop103</span><br><span class="line">[atguigu@hadoop102 .ssh]$ ssh-copy-id hadoop104</span><br></pre></td></tr></table></figure><p>3). 注意，集群机器的配置</p><ul><li><p> 还需要在hadoop103上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。</p></li><li><p> 还需要在hadoop104上采用atguigu账号配置一下无密登录到hadoop102、hadoop103、hadoop104服务器上。</p></li><li><p> 还需要在hadoop102上采用atguigu账号，配置一下无密登录到hadoop102、hadoop103、hadoop104；</p></li></ul><p>4).  .ssh文件夹下（~/.ssh）的文件功能解释</p><table><thead><tr><th>known_hosts</th><th>记录ssh访问过计算机的公钥(public  key)</th></tr></thead><tbody><tr><td>id_rsa</td><td>生成的私钥</td></tr><tr><td>id_rsa.pub</td><td>生成的公钥</td></tr><tr><td>authorized_keys</td><td>存放授权过的无密登录服务器公钥</td></tr></tbody></table><h5 id="8-集群的群起操作"><a href="#8-集群的群起操作" class="headerlink" title="8.集群的群起操作"></a>8.集群的群起操作</h5><p>​    当配置过了ssh免密登录，就可以对hadoop进行群起了（多台机器通过脚本一起启动），群起的脚本hadoop已经帮我们内置好了直接使用即可！但是要最终完成群起操作我们必须让启动/关闭脚本知道 NameNode  SecondaryNameNode  DataNode ResourceManager  NodeManager都在哪一台机器上分配，这个怎么做到呢？这个是由  hadoop安装目录下的 etc/hadoop/workers 配置文件来控制。</p><ul><li> 配置 workers 文件，内容如下：</li></ul><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hadoop102</span><br><span class="line">hadoop103</span><br><span class="line">hadoop104</span><br></pre></td></tr></table></figure><p><strong>注意：</strong>该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</p><ul><li><p>启动集群</p><p>1). <strong>如果集群是第一次启动</strong>，需要在hadoop102节点格式化NameNode（注意格式化NameNode，会产生新的集群id，导致NameNode和DataNode的集群id不一致，集群找不到已往数据。如果集群在运行过程中报错，需要重新格式化NameNode的话，一定要先停止namenode和datanode进程，并且要删除所有机器的data和logs目录，然后再进行格式化。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ hdfs namenode -format</span><br></pre></td></tr></table></figure><p>2). 启动HDFS</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh</span><br></pre></td></tr></table></figure><p>3). 在配置了ResourceManager的节点（hadoop103）启动YARN</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh</span><br></pre></td></tr></table></figure><h5 id="9-群起群停脚本的编写"><a href="#9-群起群停脚本的编写" class="headerlink" title="9.群起群停脚本的编写"></a>9.群起群停脚本的编写</h5></li></ul><p>​    上面我们已经完成对集群的群起，但是还不够完美，我们操作执行了两个脚本才启动了hdfs和yarn，虽然hadoop也给我们提供了start-all.sh 脚本，但是通常开发中不建议使用，因为start-all.sh脚本启动的话会默认启动一些不必要的组件。我们想更加完美的群起 只执行一个脚本就能把hdfs和yarn都启动或者停止。接下来我们自己封装一个脚本来实现，步骤如下：</p><p>1). 进入到/home/atguigu/bin目录下创建一个<strong>群起/群停</strong>脚本，这样操作为了在任何位置都能执行脚本</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ cd /home/atguigu/bin</span><br><span class="line">[atguigu@hadoop102 ~]$ vim mycluster.sh</span><br></pre></td></tr></table></figure><p>2). 编写脚本内容：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">if [ $# -lt 1 ]</span><br><span class="line">then</span><br><span class="line">         echo &quot;No Args Input...&quot;</span><br><span class="line">         exit</span><br><span class="line">fi</span><br><span class="line">case $1 in</span><br><span class="line">&quot;start&quot;)</span><br><span class="line">         echo &quot;==================START HDFS===================&quot; </span><br><span class="line">         ssh hadoop102 /opt/module/hadoop-3.1.3/sbin/start-dfs.sh</span><br><span class="line">         echo &quot;==================START YARN===================&quot;</span><br><span class="line">         ssh hadoop103 /opt/module/hadoop-3.1.3/sbin/start-yarn.sh</span><br><span class="line">;;</span><br><span class="line">&quot;stop&quot;)</span><br><span class="line">         echo &quot;==================STOP YARN===================&quot;</span><br><span class="line">         ssh hadoop103 /opt/module/hadoop-3.1.3/sbin/stop-yarn.sh</span><br><span class="line">         echo &quot;==================STOP HDFS===================&quot; </span><br><span class="line">         ssh hadoop102 /opt/module/hadoop-3.1.3/sbin/stop-dfs.sh</span><br><span class="line"></span><br><span class="line">;;</span><br><span class="line">*)</span><br><span class="line">  echo &quot;Input Args Error!!!!&quot;</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>3). 保存后退出，然后赋予脚本执行权限</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ chmod 777 myhadoop.sh</span><br></pre></td></tr></table></figure><p>4). 分发/home/atguigu/bin目录，保证自定义脚本在三台机器上都可以使用</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ xsync /home/atguigu/bin/</span><br></pre></td></tr></table></figure><h5 id="10-编写统一查看jps的脚本"><a href="#10-编写统一查看jps的脚本" class="headerlink" title="10.编写统一查看jps的脚本"></a>10.编写统一查看jps的脚本</h5><p>​    上面我们做了一个频繁的操作，就是总是在每一机器上输入 jps 命令，来查看当前机器的java进程，而且每次输入都是切换到服务器上输入，很麻烦，接下来我们要实现在一台机器就能查看整个集群的java进程。</p><p>1). 进入到/home/atguigu/bin目录下创建一个查看jps的脚本</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ cd /home/atguigu/bin</span><br><span class="line">[atguigu@hadoop102 ~]$ vim jpsall.sh</span><br></pre></td></tr></table></figure><p>2). 编辑脚本内容如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">for i in hadoop102 hadoop103 hadoop104</span><br><span class="line">do</span><br><span class="line">echo &quot;***************$i JPS****************&quot;</span><br><span class="line">ssh $i /opt/module/jkd1.8.0_212/bin/jps</span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>3).  保存后退出，然后赋予脚本执行权限</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ chmod 777 jpsall.sh</span><br></pre></td></tr></table></figure><p>4). 测试</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 bin]$ jpsall.sh </span><br></pre></td></tr></table></figure><p>结果如下：</p><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200823233114341.png" alt="image-20200823233114341"></p><h5 id="11-历史服务器的使用"><a href="#11-历史服务器的使用" class="headerlink" title="11.历史服务器的使用"></a>11.历史服务器的使用</h5><p>​    这一小节主要介绍hadoop的历史服务器的使用！什么是历史服务器呢？举个例子就是我们在YARN上跑的一些job的历史记录，当重启YARN后之前执行过的job任务记录就会消失，hadoop为了更好的追溯和记录这些job执行记录专门提供了一个历史服务器，只要我们在Hadoop中配置了历史服务器那么以后就可以很方便查看执行过的所有job。</p><p>1).配置mapred-site.xml</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim mapred-site.xml</span><br></pre></td></tr></table></figure><p>在该文件里面增加如下配置:</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 历史服务器端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- 历史服务器web端地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop102:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2). 分发配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ xsync $HADOOP_HOME/etc/hadoop/mapred-site.xml</span><br></pre></td></tr></table></figure><p>3). 在hadoop102启动历史服务器</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ mapred --daemon start historyserver</span><br></pre></td></tr></table></figure><p>4). 查看历史服务器是否启动</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ jps</span><br></pre></td></tr></table></figure><ol start="5"><li>web端查看历史服务器的图形化界面</li></ol><p><a href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p><h5 id="12-配置日志的聚集"><a href="#12-配置日志的聚集" class="headerlink" title="12.配置日志的聚集"></a>12.配置日志的聚集</h5><p>​    本小节主要对hadoop中的日志进行合理性的管理，方便我们更好的查阅。默认情况下 Hadoop作业执行的日志保存在hadoop的安装目录下logs下面。我们可以在linux上直接查看，但是这样操作不够人性化，查阅起来也比较麻烦。所以我们可以在执行job任务的时候产生日志后，让它自动的保存到hdfs系统中，这样就可以在网页中通过访问HDFS系统的web端地址来查看日志了！如果想完成上述操作需要我们进行以下几步配置和操作。</p><p>1）配置yarn-site.xml</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ vim yarn-site.xml</span><br></pre></td></tr></table></figure><p>内容如下：</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 开启日志聚集功能 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志聚集服务器地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://hadoop102:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>2）分发配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 hadoop]$ xsync $HADOOP_HOME/etc/hadoop/yarn-site.xml</span><br></pre></td></tr></table></figure><p>3）关闭NodeManager、ResourceManager和HistoryServer</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ stop-yarn.sh</span><br><span class="line">[atguigu@hadoop102 ~]$ mapred --daemon stop historyserver</span><br></pre></td></tr></table></figure><p>4）启动NodeManager 、ResourceManage和HistoryServer </p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ start-yarn.sh</span><br><span class="line">[atguigu@hadoop102 ~]$ mapred --daemon start historyserver</span><br></pre></td></tr></table></figure><p>5）执行wordcount程序</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ hadoop jar  $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar wordcount /input /output</span><br></pre></td></tr></table></figure><p>6）Web端查看日志</p><p>​    <a href="http://hadoop102:19888/jobhistory">http://hadoop102:19888/jobhistory</a></p><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200824172706209.png" alt="image-20200824172706209"></p><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200824172720289.png" alt="image-20200824172720289"></p><p><img src="Hadoop%E7%AC%94%E8%AE%B0%E6%80%BB%E7%BB%93-01.assets/image-20200824172736804.png" alt="image-20200824172736804"></p><h5 id="13-集群时间同步"><a href="#13-集群时间同步" class="headerlink" title="13. 集群时间同步"></a>13. 集群时间同步</h5><p>​    本小节主要操作在集群环境下，每一台服务器之间的时间同步。时间同步是很有必要的，因为在多台机器协同工作的时候，必然要求时间统一 要不然就会出问题。以下内容只要求大致了解 这项工作一般在运维的范畴。</p><p><strong>1）时间服务器配置(必须root用户</strong>)</p><p>（0）查看所有节点ntpd服务状态和开机自启动状态</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ sudo systemctl status ntpd</span><br><span class="line">[atguigu@hadoop102 ~]$ sudo systemctl is-enabled ntpd</span><br></pre></td></tr></table></figure><p>（1）在所有节点关闭ntpd服务和自启动</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ sudo systemctl stop ntpd</span><br><span class="line">[atguigu@hadoop102 ~]$ sudo systemctl disable ntpd</span><br></pre></td></tr></table></figure><p>（2）修改hadoop102的ntp.conf配置文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ sudo vim /etc/ntp.conf</span><br></pre></td></tr></table></figure><p>修改内容如下:</p><p>​    a）修改1（授权192.168.1.0-192.168.1.255网段上的所有机器可以从这台机器上查询和同步时间）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span></span><br><span class="line">改为（就是把注释去掉）：</span><br><span class="line">restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap</span><br></pre></td></tr></table></figure><p>​    b）修改2（集群在局域网中，不使用其他互联网上的时间）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">server 0.centos.pool.ntp.org iburst</span><br><span class="line">server 1.centos.pool.ntp.org iburst</span><br><span class="line">server 2.centos.pool.ntp.org iburst</span><br><span class="line">server 3.centos.pool.ntp.org iburst</span><br><span class="line">改为（都加上注释）：</span><br><span class="line"><span class="meta">#</span><span class="bash">server 0.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 1.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 2.centos.pool.ntp.org iburst</span></span><br><span class="line"><span class="meta">#</span><span class="bash">server 3.centos.pool.ntp.org iburst</span></span><br></pre></td></tr></table></figure><p>​    c）添加3（当该节点丢失网络连接，依然可以采用本地时间作为时间服务器为集群中的其他节点提供时间同步）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">server 127.127.1.0</span><br><span class="line">fudge 127.127.1.0 stratum 10</span><br></pre></td></tr></table></figure><p>（3）修改hadoop102的/etc/sysconfig/ntpd 文件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ sudo vim /etc/sysconfig/ntpd</span><br></pre></td></tr></table></figure><p>增加内容如下（让硬件时间与系统时间一起同步）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SYNC_HWCLOCK=yes</span><br></pre></td></tr></table></figure><p>（4）重新启动ntpd服务</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ sudo systemctl start ntpd</span><br></pre></td></tr></table></figure><p>（5）设置ntpd服务开机启动</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop102 ~]$ sudo systemctl enable ntpd</span><br></pre></td></tr></table></figure><p><strong>2）在其他机器进行时间同步操作（必须root用户）</strong></p><p>（1）在其他机器配置1分钟与时间服务器同步一次</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ sudo crontab -e</span><br></pre></td></tr></table></figure><p>编写定时任务如下：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">*/1 * * * * /usr/sbin/ntpdate hadoop102</span><br></pre></td></tr></table></figure><p>（2）修改任意机器时间</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ sudo date -s &quot;2018-8-08 08:08:08&quot;</span><br></pre></td></tr></table></figure><p>（3）一分钟后查看机器是否与时间服务器同步</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[atguigu@hadoop103 ~]$ sudo date</span><br></pre></td></tr></table></figure><h2 id="五、Hadoop编译源码"><a href="#五、Hadoop编译源码" class="headerlink" title="五、Hadoop编译源码"></a>五、Hadoop编译源码</h2><h2 id="六、常见错误及解决方案"><a href="#六、常见错误及解决方案" class="headerlink" title="六、常见错误及解决方案"></a>六、常见错误及解决方案</h2>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
