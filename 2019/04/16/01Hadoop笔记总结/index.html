<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="hadoop的入门学习笔记, 觉浅">
    <meta name="description" content="Jinxin Li的个人博客">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>hadoop的入门学习笔记 | 觉浅</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.3.0"></head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">觉浅</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">觉浅</div>
        <div class="logo-desc">
            
            Jinxin Li的个人博客
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="http://github.com/fourgold/" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="http://github.com/fourgold/" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/0.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">hadoop的入门学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2019-04-16
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    14.3k
                </div>
                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        
        <!-- 代码块折行 -->
        <style type="text/css">
            code[class*="language-"], pre[class*="language-"] { white-space: pre-wrap !important; }
        </style>
        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Hadoop入门"><a href="#Hadoop入门" class="headerlink" title="Hadoop入门"></a>Hadoop入门</h1><h2 id="学习目标："><a href="#学习目标：" class="headerlink" title="学习目标："></a>学习目标：</h2><ul>
<li> 了解大数据的概念以及应用场景和发展前景（这部分还是会讲故事即可）</li>
<li> 初步掌握大数据部门业务分析流程以及完整的大数据部门的组织架构（还是了解讲故事…）</li>
<li> 通俗易懂的说明白Hadoop的概念以及发展历史</li>
<li> 掌握Hadoop的前后的版本迭代更新以及Hadoop的优势</li>
<li> <strong>重点理解Hadoop框架的三大组成部分，并准确的表述各自的作用</strong></li>
<li> 掌握大数据生态的概念</li>
<li> <strong>熟练操作Hadoop运行环境的搭建（重点掌握）</strong></li>
<li> <strong>熟练掌握Hadoop的运行模式（重点掌握）</strong></li>
<li> 掌握Hadoop2.x和Hadoop3.x版本的差异</li>
<li> 能够对Hadoop的源码进行编译</li>
<li> <strong>掌握常见的错误和问题（重点）</strong></li>
</ul>
<h2 id="一、大数据概论"><a href="#一、大数据概论" class="headerlink" title="一、大数据概论"></a>一、大数据概论</h2><p><strong>前言：</strong>这部分主要讲解的就是大数据的概念，以及大数据的应用领域和发展前景，要求大家能够用自己的话去描述，讲给别人听即可！</p>
<h3 id="1-大数据的发展史"><a href="#1-大数据的发展史" class="headerlink" title="1.大数据的发展史"></a>1.大数据的发展史</h3><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">In pioneer days they used oxen for heavy pulling, and when one ox couldn’t budge a log,they didn’t try to grow a larger ox. We shouldn’t be trying for bigger computers, but formore systems of computers.
—Grace Hopper<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h3 id="2-大数据的概念"><a href="#2-大数据的概念" class="headerlink" title="2.大数据的概念"></a>2.大数据的概念</h3><p>​    大数据（big data），IT行业术语，是指无法在一定时间范围内用常规软件工具进行捕捉、管理和处理的数据集合，是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力的海量、高增长率和多样化的信息资产。</p>
<p>​    简单的讲 <strong>大数据</strong> 就是海量数据，我们想要利用这海量数据，必然要对它进行<strong>存储</strong> ，然后又想让其实现价值，必须得通过 <strong>分析计算</strong> 得到结果，而分析计算也不能没有时间限制，那就得在合理的时间内分析计算。最后一句话就是 <strong>大数据技术就是来完成海量数据的存储以及对海量数据在合理时间内进行分析运算的</strong></p>
<p>​    最小的基本单位是bit，按顺序给出所有单位：bit、Byte、KB、MB、GB、TB、PB、EB、ZB、YB、BB、NB、DB，它们按照进率1024（2的十次方）来计算：</p>
<p>8bit= 1Byte</p>
<p>1KB= 1,024 Bytes</p>
<p>1MB= 1,024 KB = 1,048,576 Bytes</p>
<p>1GB= 1,024 MB = 1,048,576 KB</p>
<p><strong>1TB= 1,024 GB = 1,048,576 MB</strong></p>
<p><strong>1PB= 1,024 TB = 1,048,576 GB</strong></p>
<p><strong>1EB= 1,024 PB = 1,048,576 TB</strong></p>
<p>1ZB= 1,024 EB = 1,048,576 PB</p>
<p>1YB= 1,024 ZB = 1,048,576 EB</p>
<p>1BB= 1,024 YB = 1,048,576 ZB</p>
<p>1NB= 1,024 BB = 1,048,576 YB</p>
<p>1 DB = 1,024 NB = 1,048,576 BB</p>
<h3 id="3-大数据的特点"><a href="#3-大数据的特点" class="headerlink" title="3.大数据的特点"></a>3.大数据的特点</h3><p>​    <strong>3.1大量（Volume）</strong></p>
<p>​    想要贴近大数据的概念，必然要求海量数据，用量化的单位来描述的话至少也得PB级别的起步。</p>
<p>​    <strong>3.2高速（Velocity）</strong></p>
<p>​    所谓的高速是指海量数据产生的速度是非常快的，例如 <strong>天猫双十一</strong> 大约1分钟左右成交100亿的，100亿背后所涉及的数据可想而知。同时数据产生速度的也要求我们对数据的处理的效率要跟上节奏才可以。</p>
<p>​    <strong>3.3多样（Variety）</strong></p>
<p>​    多样是指数据的体现形式是多样化的，大体分为三种形式  <strong>结构化数据</strong>  <strong>半结构化数据</strong>  <strong>非结构化化数据</strong>，这些所说的基本上都是原始数据，我们将来要想地数据更高效的运算都会对原始数据进行清洗。</p>
<p>​    <strong>3.4低价值密度（Value）</strong></p>
<p>​    在通常情况下，面对海量数据，往往我们需要的可能只是其中的一小部分，这就是说 <strong>价值密度的高低和数据总量是成反比的</strong> 这也是大数据比较显著的一个特点，所以 高效快速的对有价值的数据进行<strong>“提纯”</strong> 成为目前大数据领域一个攻坚破阻的难题。</p>
<h3 id="4-大数据的应用场景"><a href="#4-大数据的应用场景" class="headerlink" title="4.大数据的应用场景"></a>4.大数据的应用场景</h3><p>​    本章节主要了解大数据的真实应用场景和领域。这部分大家作为了解即可，推荐下面一片文章作为参考！</p>
<p>​    <a target="_blank" rel="noopener" href="https://www.jianshu.com/p/bb989c2fbc76">https://www.jianshu.com/p/bb989c2fbc76</a></p>
<h3 id="5-大数据的发展前景"><a href="#5-大数据的发展前景" class="headerlink" title="5.大数据的发展前景"></a>5.大数据的发展前景</h3><p>​    大数据行业的前景毋庸置疑是非常好的，从国家政策的推动再到行业的人才缺口以及未来的发展趋势都让大数据成为一个很有前途的专业。但是还是要求大家稳扎稳打 技术到家 才能翻江倒海！</p>
<h3 id="6-大数据部门业务流程分析"><a href="#6-大数据部门业务流程分析" class="headerlink" title="6.大数据部门业务流程分析"></a>6.大数据部门业务流程分析</h3><p>​    本小节主要介绍在工作当中我们将来完成一个项目的业务流程，我们大数据的工作在哪一环节崭露头角！我们大数据主要任务就是根据具体的需求对数据进行存储和分析运算，最后获取想要的数据结果。</p>
<h3 id="7-大数据部门组织结构（重点）"><a href="#7-大数据部门组织结构（重点）" class="headerlink" title="7.大数据部门组织结构（重点）"></a>7.大数据部门组织结构（重点）</h3><p>​    这一小节主要阐述一个公司通常大数据部门的智能分布，可以参考下图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%83%A8%E9%97%A8%E7%9A%84%E7%BB%84%E7%BB%87%E6%9E%B6%E6%9E%84.png" alt="大数据部门组织结构"></p>
<h2 id="二、从Hadoop框架讨论大数据生态"><a href="#二、从Hadoop框架讨论大数据生态" class="headerlink" title="二、从Hadoop框架讨论大数据生态"></a>二、从Hadoop框架讨论大数据生态</h2><h3 id="1-Hadoop的概念"><a href="#1-Hadoop的概念" class="headerlink" title="1. Hadoop的概念"></a>1. Hadoop的概念</h3><p>​    <strong>理解Hadoop是什么要从两个层面去入手：</strong></p>
<p>​    <strong>1.1 狭义：</strong>Hadoop是Apache旗下的一个用java语言实现开源软件框架，是一个开发和运行处理大规模数据的软件平台。允许使用简单的编程模型在大量计算机集群上对大型数据集进行分布式处理。它的核心组件有：</p>
<p>HDFS（分布式文件系统）：解决海量数据存储</p>
<p>YARN（作业调度和集群资源管理的框架）：解决资源任务调度</p>
<p>MAPREDUCE（分布式运算编程框架）：解决海量数据计算</p>
<p>​    <img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/hadoop图表.png" alt="image-20200815231415210" style="zoom:50%;" /></p>
<p>​    <strong>1.2 广义：</strong>广义上来说，Hadoop通常是指一个更广泛的概念——Hadoop生态圈。 </p>
<p>​    <img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/hadoop%E7%94%9F%E6%80%81%E5%9C%88.png" alt="hadoop生态圈"></p>
<p>当下的Hadoop已经成长为一个庞大的体系，随着生态系统的成长，新出现的项目越来越多，其中不乏一些非Apache主管的项目，这些项目对HADOOP是很好的补充或者更高层的抽象。比如：</p>
<p>HDFS：分布式文件系统</p>
<p>MAPREDUCE：分布式运算程序开发框架</p>
<p>HIVE：基于HADOOP的分布式数据仓库，提供基于SQL的查询数据操作</p>
<p>HBASE：基于HADOOP的分布式海量数据库</p>
<p>ZOOKEEPER：分布式协调服务基础组件</p>
<p>Mahout：基于mapreduce/spark/flink等分布式运算框架的机器学习算法库</p>
<p>OOZIE：工作流调度框架</p>
<p>Sqoop：数据导入导出工具（比如用于mysql和HDFS之间）</p>
<p>FLUME：日志数据采集框架</p>
<p>IMPALA：基于hive的实时sql查询分析</p>
<h3 id="2-Hadoop的发展史"><a href="#2-Hadoop的发展史" class="headerlink" title="2. Hadoop的发展史"></a>2. Hadoop的发展史</h3><p><img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/hadoop%E5%88%9B%E5%BB%BA%E8%80%85.png" alt="hadoop的创建者"></p>
<ol>
<li><p>2002年10月，Doug Cutting和Mike Cafarella创建了开源网页爬虫项目Nutch。</p>
</li>
<li><p>2003年10月，Google发表Google File System论文。</p>
</li>
<li><p>2004年7月，Doug Cutting和Mike Cafarella在Nutch中实现了类似GFS的功能，即后来HDFS的前身。</p>
</li>
<li><p>2004年10月，Google发表了MapReduce论文。</p>
</li>
<li><p>2005年2月，Mike Cafarella在Nutch中实现了MapReduce的最初版本。</p>
</li>
<li><p>2005年12月，开源搜索项目Nutch移植到新框架，使用MapReduce和NDFS在20个节点稳定运行。</p>
</li>
<li><p>2006年1月，Doug Cutting加入雅虎，Yahoo!提供一个专门的团队和资源将Hadoop发展成一个可在网络上运行的系统。</p>
</li>
<li><p>2006年2月，Apache Hadoop项目正式启动以支持MapReduce和HDFS的独立发展。</p>
</li>
<li><p>2006年3月，Yahoo!建设了第一个Hadoop集群用于开发。</p>
</li>
</ol>
<p>10.2006年4月，第一个Apache Hadoop发布。</p>
<p>11.2006年11月，Google发表了Bigtable论文，激起了Hbase的创建。</p>
<p>12.2007年10月，第一个Hadoop用户组会议召开，社区贡献开始急剧上升。</p>
<p>13.2007年，百度开始使用Hadoop做离线处理。</p>
<p>14.2007年，中国移动开始在“大云”研究中使用Hadoop技术。</p>
<p>15.2008年，淘宝开始投入研究基于Hadoop的系统——云梯，并将其用于处理电子商务相关数据。</p>
<p>16.2008年1月，Hadoop成为Apache顶级项目。</p>
<p>17.2008年2月，Yahoo!运行了世界上最大的Hadoop应用，宣布其搜索引擎产品部署在一个拥有1万个内核的Hadoop集群上。</p>
<p>18.2008年4月，在900个节点上运行1TB排序测试集仅需209秒，成为世界最快。</p>
<p>19.2008年8月，第一个Hadoop商业化公司Cloudera成立。</p>
<p>20.2008年10月，研究集群每天装载10TB的数据。</p>
<p>21.2009 年3月，Cloudera推出世界上首个Hadoop发行版——CDH（Cloudera’s Distribution including Apache Hadoop）平台，完全由开放源码软件组成。</p>
<p>22.2009年6月，Cloudera的工程师Tom White编写的《Hadoop权威指南》初版出版，后被誉为Hadoop圣经。</p>
<p>23.2009年7月 ，Hadoop Core项目更名为Hadoop Common;</p>
<p>24.2009年7月 ，MapReduce 和 Hadoop Distributed File System (HDFS) 成为Hadoop项目的独立子项目。</p>
<p>25.2009年8月，Hadoop创始人Doug Cutting加入Cloudera担任首席架构师。</p>
<p>26.2009年10月，首届Hadoop World大会在纽约召开。</p>
<p>27.2010年5月，IBM提供了基于Hadoop 的大数据分析软件——InfoSphere BigInsights，包括基础版和企业版。</p>
<p>28.2011年3月，Apache Hadoop获得Media Guardian Innovation Awards媒体卫报创新奖</p>
<p>29.2012年3月，企业必须的重要功能HDFS NameNode HA被加入Hadoop主版本。</p>
<p>30.2012年8月，另外一个重要的企业适用功能YARN成为Hadoop子项目。</p>
<p>31.2014年2月，Spark逐渐代替MapReduce成为Hadoop的缺省执行引擎，并成为Apache基金会顶级项目。</p>
<p>2017年12月，Release 3.0.0 generally available</p>
<h3 id="3-Hadoop三大发行版本"><a href="#3-Hadoop三大发行版本" class="headerlink" title="3. Hadoop三大发行版本"></a>3. Hadoop三大发行版本</h3><p><strong>3.1 Apache</strong></p>
<p>企业实际使用并不多。最原始（基础）版本。这是学习hadoop的基础。</p>
<p><strong>3.2 cloudera</strong></p>
<p>对hadoop的升级，打包，开发了很多框架。flume、hue、impala都是这个公司开发</p>
<p>2008 年成立的 Cloudera 是最早将 Hadoop 商用的公司，为合作伙伴提 供 Hadoop 的商用解决方案，主要是包括支持，咨询服务，培训。</p>
<p>2009年Hadoop的创始人 Doug Cutting也加盟 Cloudera公司。Cloudera 产品主要 为 CDH，Cloudera Manager，Cloudera Support</p>
<p>CDH是Cloudera的Hadoop发行版，完全开源，比Apache Hadoop在兼容性，安全 性，稳定性上有所增强。</p>
<p>Cloudera Manager是集群的软件分发及管理监控平台，可以在几个小时内部署 好一个Hadoop集群，并对集群的节点及服务进行实时监控。Cloudera Support即 是对Hadoop的技术支持。</p>
<p>Cloudera 的标价为每年每个节点4000美元。Cloudera开发并贡献了可实时处理大 数据的Impala项目。</p>
<p><strong>3.3 Hortonworks</strong></p>
<p>2011年成立的Hortonworks是雅虎与硅谷风投公司Benchmark Capital合资组建</p>
<p>公司成立之初就吸纳了大约25名至30名专门研究Hadoop的雅虎工程师，上述工 程师均在2005年开始协助雅虎开发Hadoop，贡献了Hadoop 80%的代码。</p>
<p>雅虎工程副总裁、雅虎Hadoop开发团队负责人Eric Baldeschwieler出任<br> Hortonworks的首席执行官。</p>
<p>Hortonworks 的主打产品是Hortonworks Data Platform (HDP)，也同样是100%开 源的产品，HDP除常见的项目外还包含了Ambari，一款开源的安装和管理系统</p>
<p>HCatalog，一个元数据管理系统，HCatalog现已集成到Facebook 开源的Hive中<br> 。Hortonworks的Stinger开创性地极大地优化了Hive项目。Hortonworks为入门提 供了一个非常好的，易于使用的沙盒。</p>
<p>Hortonworks开发了很多增强特性并提交至核心主干，这使得Apache Hadoop能 够在包括Windows Server和Windows Azure在内的Microsoft Windows平台上本地 运行。定价以集群为基础，每10个节点每年为12500美元。</p>
<h3 id="4-Hadoop的优势"><a href="#4-Hadoop的优势" class="headerlink" title="4. Hadoop的优势"></a>4. Hadoop的优势</h3><h5 id="4-1-高可靠性"><a href="#4-1-高可靠性" class="headerlink" title="4.1 高可靠性"></a>4.1 高可靠性</h5><p> Hadoop底层维护多个数据副本，所以即使Hadoop某个计算元素或存储出现故障，也不会导致数据的丢失。</p>
<h5 id="4-2-高可扩展性"><a href="#4-2-高可扩展性" class="headerlink" title="4.2 高可扩展性"></a>4.2 高可扩展性</h5><p> 在集群间分配任务数据，可方便的扩展数以千计的节点。</p>
<h5 id="4-3-高效性"><a href="#4-3-高效性" class="headerlink" title="4.3 高效性"></a>4.3 高效性</h5><p> 在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。</p>
<h5 id="4-4-高容错性"><a href="#4-4-高容错性" class="headerlink" title="4.4 高容错性"></a>4.4 高容错性</h5><p> 能够自动将失败的任务重新分配。</p>
<h3 id="5-Hadoop框架组成"><a href="#5-Hadoop框架组成" class="headerlink" title="5. Hadoop框架组成"></a>5. Hadoop框架组成</h3><p>Hadoop是一个能够对大量数据进行分布式处理的软件框架，以一种可靠、高效、可伸缩的方式进行数据处理，其有许多元素构成，以下是其组成元素：</p>
<p><img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/hadoop%E6%9E%B6%E6%9E%84.png" alt="hadoop结构"></p>
<p><strong>注意：</strong> 通过上图我们要掌握的重点是Hadoop是由核心的三大组件构成的，在hadoop1.x的版本中 只有两大组件分别是 <strong>HDFS(负责文件的存储)**和</strong>MapReduce(负责文件的计算和资源调度)** 。后来在hadoop2.x的时候出于架构的解耦考虑以及让 资源调度 工作能更加灵活多样化就把 原来MapReduce中的负责资源调度的功能剥离出来 单独形成 Yarn 这个核心组件。</p>
<h4 id="5-1HDFS理论概述"><a href="#5-1HDFS理论概述" class="headerlink" title="5.1HDFS理论概述"></a>5.1HDFS理论概述</h4><p><strong>HDFS:</strong> Hadoop Distributed File System(hadoop分布式文件系统)</p>
<p><strong>注意：</strong> 本小节主要是从理论的角度先去理解HDFS的概念，HDFS中还包含很多概念我们逐个来分析理解。</p>
<p><strong>1.HDFS的特点：</strong> </p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">1. 保存多个副本，且提供容错机制，副本丢失或宕机自动恢复。默认存3份。

2. 运行在廉价的机器上。

3. 适合大数据的处理。HDFS默认会将文件分割成block，64M为1个block。
   然后将block按键值对存储在HDFS上，并将键值对的映射存到内存中。如果小文件太多，那内存的负担会很  重。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>2.在HDFS中有三个重要的角色相互协调工作，分别是NameNode  SecondaryNameNode   DataNode</strong> </p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">1.NameNode   Master节点，大领导。
  -- 管理数据块映射；
  -- 处理客户端的读写请求；
  -- 配置副本策略；
  -- 管理HDFS的名称空间。 
  -- namenode 内存中存储的是 &#x3D; fsimage + edits。
     其中fsimage元数据镜像文件（文件系统的目录树），edits元数据的操作日志（针对文件系统做的修改操	  作记录）
  总之：NameNode很重要，在海量数据的存储和管理，NameNode就相当于是所有数据的描述或者指针，有了它才能进一步操作真实数据。
  
2.SecondaryNameNode  它是个小弟，分担大哥NameNode的工作量。
  -- SecondaryNameNode负责定时默认1小时，从namenode上，获取fsimage和edits来进行合并，然后再      发送给namenode。减少namenode的工作量。
  -- NameNode的冷备份。
  
3.DataNode  真实数据的存储位置
  -- 存储client发来的数据块block；
  -- 执行数据块的读写操作。
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>


<h4 id="5-2-YARN架构概述"><a href="#5-2-YARN架构概述" class="headerlink" title="5.2 YARN架构概述"></a>5.2 YARN架构概述</h4><p>​        本小节主要了解YARN架构中重要的几个 组件。本次接触YARN不要求掌握其本质原理，只要求混个脸熟，大概了解YARN的作用以及组成部分，为后面的学习建立基础。</p>
<p>​    <strong>1.为什么要用YARN？</strong></p>
<p>​        首先我们要知道的是在Hadoop1.x时代 是没有YARN的，那时候所有的数据计算以及计算过程的任务分配和资源调度都是在MapReduce中进行的，这样存在很多问题和隐患，典型的就是JobTracker容易存在单点故障和JobTracker负担重，既要负责资源管理，又要进行作业调度；当需处理太多任务时，会造成过多的资源消耗。所以在Hadoop2.x的时候，推出了YARN这套系统，其主要目的就是将Hadoop中的资源调度功能独立的分离出来，这样更方便扩展，也能高效合理的调度资源。</p>
<p>​    <strong>2.YARN中的几大角色</strong></p>
<p>​        <img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/Yarn%E7%BB%93%E6%9E%84.png" alt="yarn结构"></p>
<p>​        <strong>– ResourceManager</strong></p>
<p>​            YARN 分层结构的本质是 ResourceManager。这个实体控制整个集群并管理应用程序向基础计算资源的分配。ResourceManager 将各个资源部分（计算、内存、带宽等）精心安排给基础 NodeManager（YARN 的每节点代理）。ResourceManager 还与 ApplicationMaster 一起分配资源，与 NodeManager 一起启动和监视它们的基础应用程序。在此上下文中，ApplicationMaster 承担了以前的 TaskTracker 的一些角色，ResourceManager 承担了 JobTracker 的角色。</p>
<p>​            <strong>总的来说，RM有以下作用：</strong></p>
<pre><code>        1）处理客户端请求

        2）启动或监控ApplicationMaster</code></pre>
<p>​            3）监控NodeManager</p>
<pre><code>        4）资源的分配与调度</code></pre>
<p>​        <strong>– NodeManager</strong></p>
<p>​                ApplicationMaster 管理在YARN内运行的每个应用程序实例。ApplicationMaster 负责协调来自 ResourceManager 的资源，并通过 NodeManager 监视容器的执行和资源使用（CPU、内存等的资源分配）。请注意，尽管目前的资源更加传统（CPU 核心、内存），但未来会带来基于手头任务的新资源类型（比如图形处理单元或专用处理设备）。从 YARN 角度讲，ApplicationMaster 是用户代码，因此存在潜在的安全问题。YARN 假设 ApplicationMaster 存在错误或者甚至是恶意的，因此将它们当作无特权的代码对待。</p>
<p>​                <strong>总的来说,AM有以下作用：</strong></p>
<pre><code>            1）负责数据的切分</code></pre>
<p>​                2）为应用程序申请资源并分配给内部的任务</p>
<p>​                3）任务的监控与容错</p>
<p>​        <strong>– ApplicationMaster</strong></p>
<p>​                NodeManager管理YARN集群中的每个节点。NodeManager 提供针对集群中每个节点的服务，从监督对一个容器的终生管理到监视资源和跟踪节点健康。MRv1 通过插槽管理 Map 和 Reduce 任务的执行，而 NodeManager 管理抽象容器，这些容器代表着可供一个特定应用程序使用的针对每个节点的资源。</p>
<p>​                <strong>总的来说，NM有以下作用：</strong></p>
<pre><code>            1）管理单个节点上的资源

            2）处理来自ResourceManager的命令

            3）处理来自ApplicationMaster的命令</code></pre>
<p>​        <strong>– Container</strong></p>
<p>​            Container 是 YARN 中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等，当AM向RM申请资源时，RM为AM返回的资源便是用Container表示的。YARN会为每个任务分配一个Container，且该任务只能使用该Container中描述的资源。</p>
<p>​            <strong>总的来说，Container有以下作用：</strong></p>
<pre><code>       1）对任务运行环境进行抽象，封装CPU、内存等多维度的资源以及环境变量、启动命令等任务运行相关的信息</code></pre>
<p><strong>总结：要使用一个 YARN 集群，首先需要一个包含应用程序的客户的请求。ResourceManager 协商一个容器的必要资源，启动一个 ApplicationMaster 来表示已提交的应用程序。通过使用一个资源请求协议，ApplicationMaster 协商每个节点上供应用程序使用的资源容器。执行应用程序时，ApplicationMaster 监视容器直到完成。当应用程序完成时，ApplicationMaster 从 ResourceManager 注销其容器，执行周期就完成了。</strong></p>
<h4 id="5-3-MapReduce架构概述"><a href="#5-3-MapReduce架构概述" class="headerlink" title="5.3 MapReduce架构概述"></a>5.3 MapReduce架构概述</h4><h3 id="6-大数据技术生态体系"><a href="#6-大数据技术生态体系" class="headerlink" title="6. 大数据技术生态体系"></a>6. 大数据技术生态体系</h3><p><img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF%E7%94%9F%E6%80%81.png" alt="大数据技术生态"></p>
<p><strong>小结：</strong>大概描述就是 首先 大数据的根本就是分析计算数据，那一定要定位数据来源，数据来源大体包含三个方面，分别是 正规的数据库（结构化数据），其次还有文件日志（半结构化数据）以及通过一些爬虫手段获取的互联网数据（非结构化数据）这就组成了我们的**<em>数据来源层**</em>。 </p>
<p>​        有了数据来源接下来就需要将这些数据传输到我们的分布式文件存储系统（HDFS）或者直接通过消息队列（kafka）将数据传输到数据计算层来做数据分析和运算，这里我们把专门做数据传输的技术层称之为*<strong>数据传输层***，同时保存到HDFS中后，我们成这块内容为 *</strong>数据存储层***。</p>
<p>​        有了具体的数据那后续就可以做数据分析运算了，这时候就要有 <strong><em>数据计算层</em></strong> 来完成，这部分大概根据数据结果的实效性可以分为两类数据分析运算的场景，一种是离线运算，一种实时运算，离线的话我们通常采用MapReduce和Hive来完成。实时的话就会用到Spark体系架构完成或者用Fink框架。</p>
<p>​        结合上面提到的概念，我们还要加入 <strong><em>资源管理层</em></strong>   主要有 YARN 来完成，它的主要工作就是来分配调度计算资源的，用来协作 MapReduce 作业。同时在实行数据运算的时候 我们考虑到服务器的资源分配以及人物先后执行的顺序，有加入了一个 <strong><em>任务调度层</em></strong>  专门来控制运算作业的执行时间和先后顺序</p>
<p>​        以上就是大数据架构体系的协作规则和架构说明，但是我们最后又考虑到 分布式集群的操作，各个版块和服务一定会交叉协同工作，所以最后利用Zookeeper来统一管理 分布式集群架构。OK，以上就是关于大数据技术生态体系的话术表现。</p>
<p>​        </p>
<h3 id="7-推荐系统框架图"><a href="#7-推荐系统框架图" class="headerlink" title="7. 推荐系统框架图"></a>7. 推荐系统框架图</h3><img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/推荐系统架构图.png" alt="image-20200729111555275" style="zoom: 50%;" />

<p><strong>小结：</strong>以上的一个推荐系统的大概描述，首先一定从用户的行为开始入手，当用户购买一件商品加入购物车后，我们往往会给用户推荐相关的类似产品或者连带产品，这是目前电商系统很常见的一种营销手段。这个推荐的数据是如何产生的呢？</p>
<p>1.用户将商品加入购物车，这是会产生购物车数据，这就是我们的数据来源</p>
<p>2.利用数据传输层的相关技术将数据进行搜集处理然后通过Kafak消息队列直接将数据传输到 实时运算的框架中进行分析运算。</p>
<p>3.当 数据计算层 把数据分析运算后会得到最终的结果，根据结果为依据找到相关的类似商品的数据进行整合。</p>
<p>4.最后回到电商系统中 的推荐模块 通过调用接口的方式获取最终的分析处理后整合的商品数据的结果，将其展示到客户端页面中。</p>
<p>上面大概就是一个推荐的流程，你学到了吗！！！</p>
<h2 id="三、Hadoop运行环境搭建（重点）"><a href="#三、Hadoop运行环境搭建（重点）" class="headerlink" title="三、Hadoop运行环境搭建（重点）"></a>三、Hadoop运行环境搭建（重点）</h2><h3 id="1-虚拟机环境准备"><a href="#1-虚拟机环境准备" class="headerlink" title="1. 虚拟机环境准备"></a>1. 虚拟机环境准备</h3><ul>
<li><p><strong>1). 准备模板机</strong>（安装最小化的Linux系统）</p>
<ul>
<li><p>yum安装必要的插件</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">sudo yum install -y epel-release

sudo yum install -y psmisc nc net-tools rsync vim lrzsz ntp libzstd openssl-static tree iotop git<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>修改 /etc/hosts 文件</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">192.168.2.100 hadoop100
192.168.2.101 hadoop101
192.168.2.102 hadoop102
192.168.2.103 hadoop103
192.168.2.104 hadoop104
192.168.2.105 hadoop105
192.168.2.106 hadoop106
192.168.2.107 hadoop107
192.168.2.108 hadoop108<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>设置Linux的防火墙开机不自启</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">systemctl stop firewalld
systemctl disable firewalld<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>创建 atguigu 用户</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">useradd atguigu<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>修改/etc/sudoers文件 配置atguigu用户具有root权限</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">在第92行的位置加上以下内容
atguigu ALL&#x3D;(ALL)  NOPASSWD:ALL

:wq! 强制保存退出。<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>在/opt目录下创建两个文件夹 </p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">mkdir &#x2F;opt&#x2F;software   --放置需要安装的软件的安装包
madir &#x2F;opt&#x2F;module     --软件的安装目录<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>配置 两个文件夹 属于 atguigu 用户和 atguigu 组</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">chown atguigu:atguigu &#x2F;opt&#x2F;software

chown atguigu:atguigu &#x2F;opt&#x2F;module<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
<li><p><strong>2). 准备开发用的虚拟机</strong></p>
<ul>
<li><p>根据模板机克隆一台机器</p>
<ul>
<li> 根据克隆的步骤进行克隆就可以(参考Linux阶段的克隆操作)</li>
<li> 启动虚拟机</li>
</ul>
</li>
<li><p>修改克隆机的主机名</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">1.编辑hostname文件
vim &#x2F;etc&#x2F;hostname

2.修改主机名称
hadoop101

3.重启机器 
reboot<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>修改克隆机的ip</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">1.编辑ifcfg-ens33文件
vim &#x2F;etc&#x2F;sysconfig&#x2F;network-spcripts&#x2F;ifcfg-ens33

2.重点修改的一下标注的地方<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p> <img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/%E4%BF%AE%E6%94%B9%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%E7%BD%91%E7%BB%9C.png" alt="修改集群配置网络"></p>
</li>
<li><p>利用FinallShell工具连接Linux</p>
<p> <img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/%E9%9B%86%E7%BE%A4%E6%B5%8B%E8%AF%95.png" alt="集群测试VM"></p>
</li>
</ul>
</li>
</ul>
<h3 id="2-在准备好开发机hadoop101安装JDK"><a href="#2-在准备好开发机hadoop101安装JDK" class="headerlink" title="2. 在准备好开发机hadoop101安装JDK"></a>2. 在准备好开发机hadoop101安装JDK</h3><p>​     <strong>概述：</strong>本小节主要讲解在Linux中如何安装jdk，首先要明白Hadoop是用Java开发的，换言之Hadoop就是一款Java写的软件，那么想要运行Hadoop必然需要jdk环境。在Linux中安装Jdk和Windows中安装原理相同，只不过在Linux中Jdk的体现形式是一个 tar.gz的压缩包而Windows中是一个可视化安装程序。</p>
<ul>
<li><p><strong>1). 卸载现有JDK</strong></p>
<p> ​    <strong>注意：如果首次安装就没必要进行这一步，如果想更换jdk,非首次安装则需要先把已有的卸载掉</strong></p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">rpm -qa | grep -i java | xargs -n1 sudo rpm -e --nodeps<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p><strong>2). 将jdk的tar包导入到Linux中opt目录下的software下</strong></p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">在我们的FinallShell工具中，直接找到opt目录下的software文件夹，将Windows目录下的jdk-8u212-linux-x64.tar.gz 包拖拽到software文件夹里即可<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p><strong>3).解压jdk压缩包到opt目录下的module文件夹中</strong></p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">tar -zxvf jdk-8u212-linux-x64.tar.gz -C &#x2F;opt&#x2F;module&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p><strong>4). 配置jdk的环境变量</strong></p>
<p> <strong>概述：</strong>接下来我们就要配置jdk的环境变量，思路和在windows系统下配置环境变量类似。这里注意一下，在Linux中 我们可以通过修改 Linux的核心profile文件来添加jdk的环境变量，但是我们通常不会这么做，原因就是不希望改动Linux原有的核心文件，以免引起不必要的麻烦，那我们怎么做呢？推荐方式就是自己在指定的目录下创建一个xxx.sh文件用来充当我们自己的配置文件。当Linux系统启动后会加载profile 文件，而profile文件中的脚本会循环遍历加载 /etc/profile.d/ 目录下所有以sh为后缀名的文件，所以我们自己创建xxx.sh文件也就被加载到了。固然环境变量也就生效了！</p>
<ul>
<li><p>在/etc/profile.d/目录下新建文件 my_env.sh文件</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">sudo vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在my_env.sh文件中添加一下内容</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">#JAVA_HOME
export JAVA_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;jdk1.8.0_212
export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
<li><p>保存后退出</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">:wq<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>source 重新加载 /etc/profile文件，环境变量生效</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">source &#x2F;etc&#x2F;profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>验证jdk是否安装以及配置成功</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">java -version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> 如下图就成功了！</p>
 <img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/java的linux编译命令.png" alt="image-20200729231158594" style="zoom:80%;" />

<p> 如果没成功就reboot重启Linux，如果没问题就不用了重启！</p>
</li>
</ul>
</li>
</ul>
<h3 id="3-在开发机hadoop101安装Hadoop"><a href="#3-在开发机hadoop101安装Hadoop" class="headerlink" title="3. 在开发机hadoop101安装Hadoop"></a>3. 在开发机hadoop101安装Hadoop</h3><p><strong>概述：</strong>终于要安装hadoop了，hadoop我们把它看做适合jdk是同一类型的软件，jdk怎么操作hadoop也怎么操作就可以！</p>
<ul>
<li><p> <strong>1). 将hadoop的tar包拖拽到/opt/software目录下</strong></p>
</li>
<li><p><strong>2). 将hadoop解压缩到/opt/module目录下</strong></p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">tar -zxvf hadoop-3.1.3.tar.gz -C &#x2F;opt&#x2F;module&#x2F;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p><strong>3).配置hadoop的环境变量</strong></p>
<p> <strong>注意：</strong>hadoop中有一个特别之处，就是在hadoop的目录下的bin目录和sbin目录都是hadoop的执行脚本，所以我们在配置hadoop的环境变量的时候要注意把这两个都配上才可以！剩下其他的操作都和jdk一样了！</p>
<ul>
<li><p>打开/etc/profile.d/my_env.sh文件</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">sudo vim &#x2F;etc&#x2F;profile.d&#x2F;my_env.sh<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>在my_env.sh文件末尾添加如下内容：（shift+g）</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">#HADOOP_HOME
export HADOOP_HOME&#x3D;&#x2F;opt&#x2F;module&#x2F;hadoop-3.1.3
export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;bin
export PATH&#x3D;$PATH:$HADOOP_HOME&#x2F;sbin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p>保存退出</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">:wq<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>source 重新加载 /etc/profile文件，环境变量生效</p>
 <pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">source &#x2F;etc&#x2F;profile<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>验证hadoop是否安装以及配置成功</p>
 <pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown">hadoop version<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p> <img src="https://cdn.jsdelivr.net/gh/fourgold/images/fourgold/images/img_21_01/hadoop%E7%BC%96%E8%AF%91%E9%A2%86%E5%91%BD.png" alt="hadoop编译命令"></p>
<p> 如图所示表示安装成功！</p>
</li>
</ul>
</li>
</ul>
<h3 id="4-Hadoop目录结构"><a href="#4-Hadoop目录结构" class="headerlink" title="4. Hadoop目录结构"></a>4. Hadoop目录结构</h3><ul>
<li> <strong>bin：</strong> bin目录是Hadoop最基本的管理脚本和使用脚本所在的目录，这些脚本是sbin目录下管理脚本的基础实现，用户可以直接使用这些脚本管理和使用Hadoop</li>
<li> <strong>etc：</strong> Hadoop配置文件所在的目录，包括：core-site.xml、hdfs-site.xml、mapred-site.xml和yarn-site.xml等配置文件。</li>
<li> <strong>include：</strong>对外提供的编程库头文件（具体的动态库和静态库在lib目录中），这些文件都是用C++定义的，通常用于C++程序访问HDFS或者编写MapReduce程序。</li>
<li> <strong>lib：</strong>包含了Hadoop对外提供的编程动态库和静态库，与include目录中的头文件结合使用。</li>
<li> <strong>libexec：</strong>各个服务对应的shell配置文件所在的目录，可用于配置日志输出目录、启动参数（比如JVM参数）等基本信息。</li>
<li> <strong>sbin：</strong> Hadoop管理脚本所在目录，主要包含HDFS和YARN中各类服务启动/关闭的脚本。</li>
<li> <strong>share：</strong> Hadoop各个模块编译后的Jar包所在目录，这个目录中也包含了Hadoop文档。</li>
</ul>
<h2 id="四、Hadoop运行模式"><a href="#四、Hadoop运行模式" class="headerlink" title="四、Hadoop运行模式"></a>四、Hadoop运行模式</h2><p><strong>前言：</strong>本章节主要来学习Hadoop的运行模式，何谓运行模式呢？简单的讲就是Hadoop该如何运作起来，或者理解为玩Hadoop的游戏规则，是单台机器运行，还是多台协作运行，不同的运行模式有不一样的配置和处理。Hadoop中一共存在三种运行模式， 本地模式、伪分布式模式、完全分布式模式。</p>
<p><strong>本地模式：</strong>在一台单机上运行，没有分布式文件系统，而是直接读写本地操作系统的文件系统。</p>
<p><strong>伪分布式：</strong>这种模式也是在一台单机上运行，但用不同的Java进程模仿分布式运行中的各类结点: (NameNode,DataNode,JobTracker,TaskTracker,SecondaryNameNode) ，同理 集群中的结点由一个JobTracker和若干个TaskTracker组成，JobTracker负责任务的调度，TaskTracker负责并行执行任务。TaskTracker必须运行在DataNode上，这样便于数据的本地计算。JobTracker和NameNode则无须在同一台机器上。一个机器上，既当namenode，又当datanode,或者说 既 是jobtracker,又是tasktracker。没有所谓的在多台机器上进行真正的分布式计算，故称为”伪分布式”。</p>
<p><strong>完全分布式：</strong>真正的分布式，由3个及以上的实体机或者虚拟机组件的机群。</p>
<p><strong>注意：</strong>我们在课程中 用本地模式来入门开胃，然后集中火力做 <strong>完全分布式</strong> 伪分布式只做了解即可，没有太大意义！</p>
<h3 id="1-本地运行模式"><a href="#1-本地运行模式" class="headerlink" title="1.本地运行模式"></a>1.本地运行模式</h3><p>​    本小节主要就是感受一把Hadoop的运行过程，根据Hadoop官方提供的示例来操作几个Hadoop的基本功能点。更重要的是掌握基本操作Hadoop的步骤和思路。</p>
<p><strong>案例1需求描述：</strong>利用hadoop的grep过滤功能，将一批文件中的一些内容过滤出来。</p>
<p><strong>实现步骤：</strong></p>
<p><strong>1.1 在hadoop的解压目录创建一个文件夹input，作为需要过滤的文件的输入目录</strong></p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">mkdir input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>*<em>1.2 将hadoop目录下的 etc/hadoop/</em>.xml文件都复制到 input目录下，作为被过滤文件**</p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">cp &#x2F;etc&#x2F;hadoop&#x2F;*.xml input<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><strong>1.3 执行 bin/hadoop 命令，运行share/hadoop/mapreduce/目录下的hadoop-mapreduce-examples-3.1.3.jar包中的 grep 过滤功能，并限制一定的规则</strong></p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">bin&#x2F;hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.3.jar grep input output &#39;dfs[a-z.]+&#39;<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><strong>1.4 最后在output目录下查看过滤的结果即可！</strong></p>
<p><strong>案例2需求描述：</strong>利用Hadoop完成经典wordcount(单词统计)，就是针对一些文件计算统计里面相同单词的个数。</p>
<p><strong>实现步骤：</strong></p>
<p><strong>1.1 创建在hadoop-3.1.3文件下面创建一个wcinput文件夹</strong></p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">mkdir wcinput<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><strong>1.2 在wcinput文件下创建一个word.txt文件</strong></p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">cd wcinput<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><strong>1.3 编辑word.txt文件</strong></p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">vim word.txt

在文件中输入如下内容(内容随意)
hadoop yarn
hadoop mapreduce
atguigu
atguigu<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>1.4 回到Hadoop目录/opt/module/hadoop-3.1.3</strong>  <strong>执行程序</strong></p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark">hadoop jar share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p><strong>1.5 查看结果</strong></p>
<pre class="line-numbers language-mark" data-language="mark"><code class="language-mark"> cat wcoutput&#x2F;part-r-00000
 
看到如下结果：
atguigu 2
hadoop  2
mapreduce 1
yarn    1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="2-完全分布式运行模式-重点掌握"><a href="#2-完全分布式运行模式-重点掌握" class="headerlink" title="2.完全分布式运行模式(重点掌握)"></a>2.完全分布式运行模式(重点掌握)</h3><p>​    本章节是重中之重，主要讲解完全分布式运行模式。</p>
<h4 id="2-1-准备3台服务器"><a href="#2-1-准备3台服务器" class="headerlink" title="2.1 准备3台服务器"></a>2.1 准备3台服务器</h4><p>为了满足集群的环境，我们需要准备三台服务器，准备方式就是根据我们之前做好的模板机进行克隆即可，但是需要注意，三台服务器的的 静态ip地址和主机名都要修改一下，以便区分！</p>
<h5 id="2-1-1-克隆第一台"><a href="#2-1-1-克隆第一台" class="headerlink" title="2.1.1 克隆第一台"></a>2.1.1 克隆第一台</h5><p>修改主机名为hadoop102</p>
<p>修改ip地址为：192.168.2.102</p>
<h5 id="2-1-2-克隆第二台"><a href="#2-1-2-克隆第二台" class="headerlink" title="2.1.2 克隆第二台"></a>2.1.2 克隆第二台</h5><p>修改主机名为hadoop103</p>
<p>修改ip地址为：192.168.2.103</p>
<h5 id="2-1-3-克隆第三台"><a href="#2-1-3-克隆第三台" class="headerlink" title="2.1.3 克隆第三台"></a>2.1.3 克隆第三台</h5><p>修改主机名为hadoop104</p>
<p>修改ip地址为：192.168.2.104</p>
<h4 id="2-2-集群分发脚本的应用场景"><a href="#2-2-集群分发脚本的应用场景" class="headerlink" title="2.2 集群分发脚本的应用场景"></a>2.2 集群分发脚本的应用场景</h4><p><strong>场景介绍：</strong></p>
<p>​        上面我们已经准备好了三台服务器，并且都各自修改了主机名和ip地址。但是我们知道 需要额必备软件以及环境变量还没有配置，如果机械的一台一台配置也可以但是这样会引发大量的重复性工作，没有必要。如何能避免重复配置呢，最好是值在一台机器进行修改 然后将修改的配置信息同步到集群的所有机器那就完美了！这时候就要用到 分发脚本 的方案！</p>
<h5 id="2-2-1-scp-安全拷贝"><a href="#2-2-1-scp-安全拷贝" class="headerlink" title="2.2.1 scp 安全拷贝"></a>2.2.1 scp 安全拷贝</h5><p><strong>scp含义：</strong></p>
<p>​    scp命令可以实现服务器与服务器之间的数据拷贝</p>
<p><strong>基本语法：</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">scp</span>	-r	<span class="token variable">$pdir</span>/<span class="token variable">$fname</span> <span class="token variable">$user</span>@hadoop<span class="token variable">$host</span><span class="token builtin class-name">:</span><span class="token variable">$pdir</span>/<span class="token variable">$fname</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>​    命令  递归    要拷贝的文件路径/名称   目的用户@主机:目的路径/名称</p>
<p><strong>案例实操：</strong></p>
<p>前提：在 hadoop102 hadoop103 hadoop104 都已经创建好的 /opt/module</p>
<p>​      /opt/software 两个目录， 并且已经把这两个目录修改为atguigu:atguigu</p>
<p>​      sudo chown atguigu:atguigu -R /opt/module</p>
<p>1).在hadoop101上，将hadoop101中/opt/module/目录下所有内容拷贝到hadoop102上的/opt/module/目录下。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">scp</span> -r /opt/module/* atguigu@hadoop102:/opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>2).在hadoop103上，将hadoop101中/opt/module/目录下的所有内容拷贝到hadoop103的/opt/module/目录下。</p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash"><span class="token function">scp</span> -r atguigu@hadoop101:/opt/module/* /opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>3).在hadoop103上，将hadoop101中/opt/module/目录下的所有内容拷贝到hadoop104的/opt/module/目录下。</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">scp</span> -r atguigu@hadoop101:/opt/module/* atguigu@hadoop104:/opt/module/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>4).在任意一台机器上，将hadoop101中的/etc/profile.d目录下的my_env.sh配置文件分别复制到hadoop102、hadoop103、hadoop104上</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token number">1</span>. <span class="token function">scp</span> -r /etc/profile.d/my_env.sh root@hadoop102:/etc/profile.d/
<span class="token number">2</span>. <span class="token function">scp</span> -r /etc/profile.d/my_env.sh root@hadoop103:/etc/profile.d/
<span class="token number">3</span>. <span class="token function">scp</span> -r /etc/profile.d/my_env.sh root@hadoop104:/etc/profile.d/<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h5 id="2-2-2-rsync远程同步工具"><a href="#2-2-2-rsync远程同步工具" class="headerlink" title="2.2.2 rsync远程同步工具"></a>2.2.2 rsync远程同步工具</h5><p><strong>功能描述：</strong></p>
<p>​        rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p>
<p><strong>rsync和scp区别：</strong></p>
<p>​        用rsync做文件的复制要比scp的速度快，rsync只对差异文件做更新。scp是把所有文件都复制过去。</p>
<p><strong>基本语法：</strong></p>
<p>rsync   -av    $pdir/$fname        $user@hadoop$host:$pdir/$fname</p>
<p>命令  选项参数  要拷贝的文件路径/名称  目的用户@主机:目的路径/名称</p>
<p>​     选项参数说明</p>
<table>
<thead>
<tr>
<th>选项</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>-a</td>
<td>归档拷贝</td>
</tr>
<tr>
<td>-v</td>
<td>显示复制过程</td>
</tr>
</tbody></table>
<p><strong>案例实操:</strong></p>
<p>把hadoop102机器上的/opt/software目录同步到hadoop103服务器的/opt/software目录下（没有实际意义的操作只是为了练手）</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">rsync</span> -av /opt/software/* atguigu@hadoop103:/opt/software/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h5 id="2-2-3-分发脚本的应用"><a href="#2-2-3-分发脚本的应用" class="headerlink" title="2.2.3 分发脚本的应用"></a>2.2.3 分发脚本的应用</h5><p><strong>概述：</strong>前面其实我们已经是实现了服务器之间的文件目录拷贝传递了，但是每次都得执行命令来实现，还是比较麻烦的，干脆一步到位，通过编写一个脚本 通过执行脚本来实现信息拷贝。</p>
<p><strong>前提：</strong> 在/home/atguigu/bin这个目录下存放的脚本，atguigu用户可以在系统任何地方直接执行。</p>
<p><strong>脚本实现：</strong></p>
<p>1). 在/home/atguigu/bin目录下创建xsync文件</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token punctuation">[</span>atguigu@hadoop102 opt<span class="token punctuation">]</span>$ <span class="token builtin class-name">cd</span> /home/atguigu
<span class="token punctuation">[</span>atguigu@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token function">mkdir</span> bin
<span class="token punctuation">[</span>atguigu@hadoop102 ~<span class="token punctuation">]</span>$ <span class="token builtin class-name">cd</span> bin
<span class="token punctuation">[</span>atguigu@hadoop102 bin<span class="token punctuation">]</span>$ <span class="token function">vim</span> xsync<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>2). 在该文件中编写如下代码</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token shebang important">#!/bin/bash</span>
<span class="token comment">#1. 判断参数个数</span>
<span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token variable">$#</span> -lt <span class="token number">1</span> <span class="token punctuation">]</span>
<span class="token keyword">then</span>
  <span class="token builtin class-name">echo</span> Not Enough Arguement<span class="token operator">!</span>
  <span class="token builtin class-name">exit</span><span class="token punctuation">;</span>
<span class="token keyword">fi</span>
<span class="token comment">#2. 遍历集群所有机器</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">host</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
<span class="token keyword">do</span>
  <span class="token builtin class-name">echo</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>  <span class="token variable">$host</span>  <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
  <span class="token comment">#3. 遍历所有目录，挨个发送</span>
  <span class="token keyword">for</span> <span class="token for-or-select variable">file</span> <span class="token keyword">in</span> <span class="token variable">$@</span>
  <span class="token keyword">do</span>
    <span class="token comment">#4. 判断文件是否存在</span>
    <span class="token keyword">if</span> <span class="token punctuation">[</span> -e <span class="token variable">$file</span> <span class="token punctuation">]</span>
    <span class="token keyword">then</span>
      <span class="token comment">#5. 获取父目录</span>
      <span class="token assign-left variable">pdir</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">cd</span> -P <span class="token punctuation">$(</span>dirname $file<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token builtin class-name">pwd</span><span class="token variable">)</span></span>
      <span class="token comment">#6. 获取当前文件的名称</span>
      <span class="token assign-left variable">fname</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token function">basename</span> $file<span class="token variable">)</span></span>
      <span class="token function">ssh</span> <span class="token variable">$host</span> <span class="token string">"mkdir -p <span class="token variable">$pdir</span>"</span>
      <span class="token function">rsync</span> -av <span class="token variable">$pdir</span>/<span class="token variable">$fname</span> <span class="token variable">$host</span><span class="token builtin class-name">:</span><span class="token variable">$pdir</span>
    <span class="token keyword">else</span>
      <span class="token builtin class-name">echo</span> <span class="token variable">$file</span> does not exists<span class="token operator">!</span>
    <span class="token keyword">fi</span>
  <span class="token keyword">done</span>
<span class="token keyword">done</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>3). 修改文件的执行权限</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">chmod</span> <span class="token number">777</span> xsync<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>4). 将脚本复制到/bin中，以便全局调用</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">cp</span> xsync /bin/<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>5). 测试脚本</p>
<pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">xsync test.txt<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h4 id="2-3-分布式集群规划"><a href="#2-3-分布式集群规划" class="headerlink" title="2.3 分布式集群规划"></a>2.3 分布式集群规划</h4><p>​    <strong>概述：</strong>接下来我们就要搭建Hadoop集群了，在操作之前一定要有具体的集群规划，集群规划其实就是把Hadoop中的核心组件如何安排到每台机器上。</p>
<p>​    <strong>分析：</strong> 通过前面的介绍我们知道 在Hadoop集群当中先要考虑数据的存储以及资源调度的安排。那就会涉及到NameNode 、ResourceManager 、SecondaryNameNode 、DataNode 、 NodeManager。如何把这些组件分布到每一台机器上，就得合理分析一下。</p>
<p>NameNode 、ResourceManager 、SecondaryNameNode 这三个组件相对来说比较耗费资源，我们通常把他们分布到不同的机器上。所以三台机器每一台分布一个。</p>
<p>DataNode是具体存储数据的，因为三台机器都具备存储空间，那每一台都分布一个DataNode</p>
<p>NodeManager是负责每一台机器的资源的管理，因此三台机器每一台也分布一个NodeManager</p>
<p><strong>hadoop102            NameNode                         DataNode              NodeManager</strong></p>
<p><strong>hadoop103            ResourceManager              DataNode              NodeManager</strong></p>
<p><strong>hadoop104            SecondaryNameNode      DataNode                NodeManager</strong></p>
<h4 id="2-4-搭建完全集群"><a href="#2-4-搭建完全集群" class="headerlink" title="2.4 搭建完全集群"></a>2.4 搭建完全集群</h4><h5 id="1-先删除每个节点中hadoop安装目录下的-data-和-logs目录，如果是最新解压配置的hadoop集群，并没有这两个目录就不需要进行删除这步。"><a href="#1-先删除每个节点中hadoop安装目录下的-data-和-logs目录，如果是最新解压配置的hadoop集群，并没有这两个目录就不需要进行删除这步。" class="headerlink" title="1.先删除每个节点中hadoop安装目录下的 data 和 logs目录，如果是最新解压配置的hadoop集群，并没有这两个目录就不需要进行删除这步。"></a><strong>1.先删除每个节点中hadoop安装目录下的 data 和 logs目录，如果是最新解压配置的hadoop集群，并没有这两个目录就不需要进行删除这步。</strong></h5><h5 id="2-在hadoop-env-sh文件中，配置JAVA-HOME-的环境变量，这是因为Hadoop运行的时候需要java的环境变量。"><a href="#2-在hadoop-env-sh文件中，配置JAVA-HOME-的环境变量，这是因为Hadoop运行的时候需要java的环境变量。" class="headerlink" title="2.在hadoop-env.sh文件中，配置JAVA_HOME 的环境变量，这是因为Hadoop运行的时候需要java的环境变量。"></a><strong>2.在hadoop-env.sh文件中，配置JAVA_HOME 的环境变量，这是因为Hadoop运行的时候需要java的环境变量。</strong></h5><h5 id="3-配置Hadoop的4大核心配置文件"><a href="#3-配置Hadoop的4大核心配置文件" class="headerlink" title="3.配置Hadoop的4大核心配置文件"></a><strong>3.配置Hadoop的4大核心配置文件</strong></h5><ul>
<li><p><strong>core-site.xml</strong>  这个是hadoop总的核心配置文件，集群加载启动的时候首先会加载解析此配置文件，具体配置内容如下：</p>
 <pre class="line-numbers language-xml" data-language="xml"><code class="language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?></span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?></span>
<span class="token comment">&lt;!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
--></span>

<span class="token comment">&lt;!-- Put site-specific property overrides in this file. --></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">></span></span>
    <span class="token comment">&lt;!--cmeNode的地址 --></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>hdfs://hadoop102:9820<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token comment">&lt;!-- 指定hadoop数据的存储目录 --></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.data.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>/opt/module/hadoop-3.1.3/data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>

    
    <span class="token comment">&lt;!-- 配置该atguigu(superUser)允许通过代理访问的主机节点 --></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.atguigu.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token comment">&lt;!-- 配置该atguigu(superUser)允许通过代理用户所属组 --></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.atguigu.groups<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
    <span class="token comment">&lt;!-- 配置该atguigu(superUser)允许通过代理的用户--></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hadoop.proxyuser.atguigu.users<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><spa